# Story 3.4: PipeCat Client Connection and Audio Setup

**Epic:** Epic 3 - Voice Calling Integration  
**Status:** Draft  
**Created:** December 20, 2025  
**Last Updated:** December 20, 2025

---

## Story

**As a** student user,  
**I want** the voice session page to connect me to the Daily.co room and establish audio communication with the counselor bot,  
**so that** I can have a real-time voice conversation.

---

## Acceptance Criteria

1. Voice session page (/voice-session) extracts room credentials (room_url, user_token, session_id) from URL query params.
2. Page initializes RTVIClient from @pipecat-ai/rtvi-client-web with DailyTransport.
3. Client connects to Daily.co room using room URL and user token.
4. Page requests microphone permissions and initializes local audio input.
5. Page displays connection status: "Connecting...", "Connected", or "Disconnected".
6. User can hear bot's voice responses through speakers/headphones.
7. Bot can hear user's voice input through microphone.
8. Page handles connection errors with retry functionality.
9. Page has "End Session" button that disconnects client and navigates back to dashboard.

---

## Tasks / Subtasks

- [ ] Install PipeCat client dependencies (AC: 2)
  - [ ] Add @pipecat-ai/rtvi-client-web to package.json
  - [ ] Add @daily-co/daily-js for DailyTransport
  - [ ] Install necessary types (@types/daily-js)
  - [ ] Document version compatibility
  
- [ ] Create VoiceSessionPage component (AC: 1)
  - [ ] Extract query params (room_url, user_token, session_id, category)
  - [ ] Validate required params are present
  - [ ] Show error UI if params missing
  - [ ] Display counselor category name
  
- [ ] Initialize RTVIClient (AC: 2, 3)
  - [ ] Import RTVIClient and DailyTransport
  - [ ] Configure client with room URL and token
  - [ ] Set up event listeners (connected, disconnected, error)
  - [ ] Connect client on component mount
  - [ ] Handle connection lifecycle
  
- [ ] Request microphone permissions (AC: 4)
  - [ ] Use navigator.mediaDevices.getUserMedia
  - [ ] Handle permission denied scenario
  - [ ] Show permission prompt UI
  - [ ] Enable audio input when granted
  
- [ ] Implement connection status UI (AC: 5)
  - [ ] Create ConnectionStatus component
  - [ ] Show "Connecting..." spinner during connection
  - [ ] Show "Connected" with green indicator
  - [ ] Show "Disconnected" with red indicator and retry
  - [ ] Display connection quality indicator
  
- [ ] Set up audio playback (AC: 6)
  - [ ] Configure Daily.co audio output
  - [ ] Test bot voice responses audible
  - [ ] Handle audio device selection
  - [ ] Add volume control (Story 3.6)
  
- [ ] Set up audio input (AC: 7)
  - [ ] Configure Daily.co microphone input
  - [ ] Test user voice transmitted to bot
  - [ ] Show microphone indicator (active/muted)
  - [ ] Add mute button (Story 3.6)
  
- [ ] Implement error handling (AC: 8)
  - [ ] Handle connection timeout
  - [ ] Handle network disconnection
  - [ ] Handle permission denied
  - [ ] Show retry button on errors
  - [ ] Log errors for debugging
  
- [ ] Implement session end functionality (AC: 9)
  - [ ] Add "End Session" button
  - [ ] Show confirmation dialog
  - [ ] Disconnect RTVIClient
  - [ ] Clean up audio resources
  - [ ] Navigate to dashboard
  - [ ] Show session summary (optional)
  
- [ ] Write comprehensive tests
  - [ ] Unit test client initialization
  - [ ] Mock RTVIClient connection
  - [ ] Test permission handling
  - [ ] Test error scenarios
  - [ ] Test session end flow
  - [ ] Integration test full connection flow

---

## Dev Notes

### Architecture Overview (From Architecture Document)

**RTVIClient (PipeCat Web SDK):**
- Wrapper around Daily.co JavaScript SDK
- Handles WebRTC connection, audio streaming, and bot communication
- Event-driven architecture for real-time updates
- Manages STT/TTS pipeline coordination

**Connection Flow:**
1. User lands on /voice-session with room credentials
2. RTVIClient initialized with DailyTransport
3. Client connects to Daily.co room
4. Microphone permission requested
5. Bot already in room (spawned by backend in Story 3.1)
6. Audio streams established bidirectionally
7. User speaks → Bot hears → Bot responds → User hears

**WebRTC Considerations:**
- Network quality affects latency
- Firewall/NAT traversal handled by Daily.co
- Fallback to TURN servers if direct connection fails

### Voice Session Page Implementation

**app/voice-session/page.tsx:**
```typescript
'use client';

import { useEffect, useState, useRef, Suspense } from 'react';
import { useRouter, useSearchParams } from 'next/navigation';
import { RTVIClient } from '@pipecat-ai/rtvi-client-web';
import DailyTransport from '@pipecat-ai/rtvi-client-web/daily';
import { Button } from '@/components/ui/button';
import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';
import { AlertDialog, AlertDialogAction, AlertDialogCancel, AlertDialogContent, AlertDialogDescription, AlertDialogFooter, AlertDialogHeader, AlertDialogTitle } from '@/components/ui/alert-dialog';
import { PhoneOff, Loader2, Mic, MicOff } from 'lucide-react';
import { useToast } from '@/components/ui/use-toast';

type ConnectionState = 'idle' | 'connecting' | 'connected' | 'disconnected' | 'error';

function VoiceSessionContent() {
  const searchParams = useSearchParams();
  const router = useRouter();
  const { toast } = useToast();

  // Extract room credentials from URL
  const roomUrl = searchParams.get('room_url');
  const userToken = searchParams.get('user_token');
  const sessionId = searchParams.get('session_id');
  const category = searchParams.get('category') || 'Counselor';

  // State
  const [connectionState, setConnectionState] = useState<ConnectionState>('idle');
  const [isMuted, setIsMuted] = useState(false);
  const [showEndDialog, setShowEndDialog] = useState(false);
  const [permissionDenied, setPermissionDenied] = useState(false);

  // Refs
  const rtviClientRef = useRef<RTVIClient | null>(null);
  const hasConnected = useRef(false);

  // Validate params
  useEffect(() => {
    if (!roomUrl || !userToken || !sessionId) {
      toast({
        title: "Invalid Session",
        description: "Missing required session parameters. Returning to dashboard.",
        variant: "destructive"
      });
      router.push('/dashboard');
    }
  }, [roomUrl, userToken, sessionId, router, toast]);

  // Initialize RTVI Client and connect
  useEffect(() => {
    if (!roomUrl || !userToken || hasConnected.current) return;

    const initializeClient = async () => {
      try {
        setConnectionState('connecting');

        // Request microphone permission
        try {
          await navigator.mediaDevices.getUserMedia({ audio: true });
        } catch (permError) {
          console.error('Microphone permission denied:', permError);
          setPermissionDenied(true);
          setConnectionState('error');
          toast({
            title: "Microphone Required",
            description: "Please allow microphone access to join the voice session.",
            variant: "destructive"
          });
          return;
        }

        // Initialize RTVIClient with DailyTransport
        const client = new RTVIClient({
          transport: new DailyTransport(),
          params: {
            baseUrl: roomUrl,
            token: userToken,
            enableMic: true,
            enableCam: false, // Voice-only for now
          },
          timeout: 15000, // 15 second connection timeout
        });

        // Event listeners
        client.on('connected', () => {
          console.log('RTVI Client connected');
          setConnectionState('connected');
          toast({
            title: "Connected",
            description: `You're now connected to ${category}. Start speaking!`
          });
        });

        client.on('disconnected', () => {
          console.log('RTVI Client disconnected');
          setConnectionState('disconnected');
        });

        client.on('error', (error: any) => {
          console.error('RTVI Client error:', error);
          setConnectionState('error');
          toast({
            title: "Connection Error",
            description: "Lost connection to the session. Please try reconnecting.",
            variant: "destructive"
          });
        });

        // Connect to room
        await client.connect();
        rtviClientRef.current = client;
        hasConnected.current = true;

      } catch (error) {
        console.error('Failed to initialize RTVI client:', error);
        setConnectionState('error');
        toast({
          title: "Connection Failed",
          description: error instanceof Error ? error.message : "Unable to connect to voice session.",
          variant: "destructive"
        });
      }
    };

    initializeClient();

    // Cleanup on unmount
    return () => {
      if (rtviClientRef.current) {
        rtviClientRef.current.disconnect();
        rtviClientRef.current = null;
      }
    };
  }, [roomUrl, userToken, category, toast]);

  // Mute/Unmute microphone
  const toggleMute = async () => {
    if (!rtviClientRef.current) return;

    try {
      if (isMuted) {
        await rtviClientRef.current.enableMic();
        setIsMuted(false);
      } else {
        await rtviClientRef.current.disableMic();
        setIsMuted(true);
      }
    } catch (error) {
      console.error('Failed to toggle mute:', error);
    }
  };

  // End session handler
  const handleEndSession = async () => {
    if (rtviClientRef.current) {
      await rtviClientRef.current.disconnect();
    }
    
    toast({
      title: "Session Ended",
      description: "Your counseling session has ended. Take care!"
    });
    
    router.push('/dashboard');
  };

  // Retry connection
  const retryConnection = () => {
    hasConnected.current = false;
    setConnectionState('idle');
    window.location.reload(); // Simple retry via reload
  };

  // Render connection status
  const renderConnectionStatus = () => {
    switch (connectionState) {
      case 'connecting':
        return (
          <div className="flex items-center gap-2 text-blue-600">
            <Loader2 className="h-4 w-4 animate-spin" />
            <span>Connecting to {category}...</span>
          </div>
        );
      case 'connected':
        return (
          <div className="flex items-center gap-2 text-green-600">
            <div className="h-3 w-3 rounded-full bg-green-600 animate-pulse" />
            <span>Connected</span>
          </div>
        );
      case 'disconnected':
        return (
          <div className="flex items-center gap-2 text-red-600">
            <div className="h-3 w-3 rounded-full bg-red-600" />
            <span>Disconnected</span>
          </div>
        );
      case 'error':
        return (
          <div className="flex flex-col gap-2">
            <div className="flex items-center gap-2 text-red-600">
              <div className="h-3 w-3 rounded-full bg-red-600" />
              <span>Connection Error</span>
            </div>
            <Button onClick={retryConnection} variant="outline" size="sm">
              Retry Connection
            </Button>
          </div>
        );
      default:
        return null;
    }
  };

  // Handle permission denied state
  if (permissionDenied) {
    return (
      <div className="container mx-auto flex items-center justify-center min-h-screen p-4">
        <Card className="max-w-md">
          <CardHeader>
            <CardTitle>Microphone Access Required</CardTitle>
          </CardHeader>
          <CardContent className="space-y-4">
            <p className="text-muted-foreground">
              Voice calling requires microphone access. Please enable microphone permissions in your browser settings and reload the page.
            </p>
            <div className="flex gap-2">
              <Button onClick={() => window.location.reload()} className="flex-1">
                Try Again
              </Button>
              <Button onClick={() => router.push('/dashboard')} variant="outline" className="flex-1">
                Go Back
              </Button>
            </div>
          </CardContent>
        </Card>
      </div>
    );
  }

  return (
    <div className="container mx-auto flex flex-col items-center justify-center min-h-screen p-4">
      <Card className="w-full max-w-2xl">
        <CardHeader>
          <div className="flex items-center justify-between">
            <CardTitle>Voice Session: {category}</CardTitle>
            {renderConnectionStatus()}
          </div>
        </CardHeader>
        <CardContent className="space-y-6">
          {/* Audio visualization placeholder (Story 3.5 will add transcript) */}
          <div className="flex items-center justify-center p-12 bg-muted rounded-lg">
            <div className="text-center space-y-4">
              <div className="text-6xl">
                {isMuted ? <MicOff className="mx-auto" /> : <Mic className="mx-auto animate-pulse" />}
              </div>
              <p className="text-muted-foreground">
                {connectionState === 'connected' 
                  ? isMuted 
                    ? 'Microphone muted. Click to unmute.'
                    : 'Listening... Speak freely.'
                  : 'Connecting...'}
              </p>
            </div>
          </div>

          {/* Session controls */}
          <div className="flex gap-3 justify-center">
            <Button
              onClick={toggleMute}
              variant={isMuted ? 'destructive' : 'secondary'}
              disabled={connectionState !== 'connected'}
              className="flex-1 max-w-xs"
            >
              {isMuted ? <MicOff className="mr-2 h-4 w-4" /> : <Mic className="mr-2 h-4 w-4" />}
              {isMuted ? 'Unmute' : 'Mute'}
            </Button>
            
            <Button
              onClick={() => setShowEndDialog(true)}
              variant="destructive"
              className="flex-1 max-w-xs"
            >
              <PhoneOff className="mr-2 h-4 w-4" />
              End Session
            </Button>
          </div>

          {/* Session info */}
          <div className="text-xs text-muted-foreground text-center space-y-1">
            <p>Session ID: {sessionId}</p>
            <p>If you're in crisis, call 988 (Suicide & Crisis Lifeline) immediately.</p>
          </div>
        </CardContent>
      </Card>

      {/* End session confirmation dialog */}
      <AlertDialog open={showEndDialog} onOpenChange={setShowEndDialog}>
        <AlertDialogContent>
          <AlertDialogHeader>
            <AlertDialogTitle>End Voice Session?</AlertDialogTitle>
            <AlertDialogDescription>
              Are you sure you want to end this counseling session? You can always start a new session from the dashboard.
            </AlertDialogDescription>
          </AlertDialogHeader>
          <AlertDialogFooter>
            <AlertDialogCancel>Stay in Session</AlertDialogCancel>
            <AlertDialogAction onClick={handleEndSession}>
              End Session
            </AlertDialogAction>
          </AlertDialogFooter>
        </AlertDialogContent>
      </AlertDialog>
    </div>
  );
}

export default function VoiceSessionPage() {
  return (
    <Suspense fallback={
      <div className="flex items-center justify-center min-h-screen">
        <Loader2 className="h-8 w-8 animate-spin" />
      </div>
    }>
      <VoiceSessionContent />
    </Suspense>
  );
}
```

### TypeScript Types

**types/voice.ts:**
```typescript
export type ConnectionState = 'idle' | 'connecting' | 'connected' | 'disconnected' | 'error';

export interface VoiceSessionParams {
  room_url: string;
  user_token: string;
  session_id: string;
  category: string;
}

export interface RTVIClientConfig {
  transport: any; // DailyTransport
  params: {
    baseUrl: string;
    token: string;
    enableMic: boolean;
    enableCam: boolean;
  };
  timeout: number;
}
```

### Environment Variables

No additional env vars needed for frontend. Daily.co authentication handled by user token from backend.

### Source Tree Updates

```
packages/frontend/
├── app/
│   └── voice-session/
│       └── page.tsx              # Full voice session implementation
├── types/
│   └── voice.ts                  # Voice session types
└── components/
    └── ui/
        └── alert-dialog.tsx      # shadcn/ui component (if not already present)
```

### WebRTC Troubleshooting Guide

**Common Issues:**

1. **Microphone not working:**
   - Check browser permissions
   - Verify correct input device selected
   - Test with other apps

2. **Cannot hear bot:**
   - Check speaker/headphone volume
   - Verify correct output device
   - Check Daily.co audio routing

3. **Connection timeout:**
   - Check firewall settings
   - Verify network connectivity
   - Daily.co will use TURN servers as fallback

4. **Echo or feedback:**
   - Use headphones
   - Enable echo cancellation (handled by Daily.co)

---

## Testing

### Testing Standards

**Test Locations:**
- Component tests: `__tests__/app/voice-session/page.test.tsx`
- Integration tests: `e2e/voice-session.spec.ts`

**Testing Framework:**
- Vitest with React Testing Library
- Playwright for E2E
- Mock RTVIClient for unit tests

**Testing Requirements:**

1. **Client Initialization Test:**
   ```typescript
   import { render, screen, waitFor } from '@testing-library/react';
   import { vi } from 'vitest';
   import VoiceSessionPage from '@/app/voice-session/page';
   import { RTVIClient } from '@pipecat-ai/rtvi-client-web';

   vi.mock('@pipecat-ai/rtvi-client-web');
   vi.mock('next/navigation');

   describe('VoiceSessionPage', () => {
     const mockSearchParams = {
       get: vi.fn((key: string) => {
         const params: any = {
           room_url: 'https://test.daily.co/room',
           user_token: 'token-123',
           session_id: 'session-456',
           category: 'Health Counselor'
         };
         return params[key];
       })
     };

     beforeEach(() => {
       vi.mocked(useSearchParams).mockReturnValue(mockSearchParams as any);
       
       // Mock getUserMedia
       global.navigator.mediaDevices = {
         getUserMedia: vi.fn().mockResolvedValue({})
       } as any;
     });

     it('initializes RTVIClient with correct params', async () => {
       const mockClient = {
         connect: vi.fn().mockResolvedValue(undefined),
         on: vi.fn(),
         disconnect: vi.fn()
       };

       vi.mocked(RTVIClient).mockImplementation(() => mockClient as any);

       render(<VoiceSessionPage />);

       await waitFor(() => {
         expect(RTVIClient).toHaveBeenCalledWith(
           expect.objectContaining({
             params: expect.objectContaining({
               baseUrl: 'https://test.daily.co/room',
               token: 'token-123'
             })
           })
         );
       });

       expect(mockClient.connect).toHaveBeenCalled();
     });

     it('shows connecting state initially', () => {
       render(<VoiceSessionPage />);
       expect(screen.getByText(/connecting to health counselor/i)).toBeInTheDocument();
     });

     it('handles microphone permission denied', async () => {
       global.navigator.mediaDevices.getUserMedia = vi.fn().mockRejectedValue(
         new Error('Permission denied')
       );

       render(<VoiceSessionPage />);

       await waitFor(() => {
         expect(screen.getByText(/microphone access required/i)).toBeInTheDocument();
       });
     });

     it('handles connection error', async () => {
       const mockClient = {
         connect: vi.fn().mockRejectedValue(new Error('Connection failed')),
         on: vi.fn(),
         disconnect: vi.fn()
       };

       vi.mocked(RTVIClient).mockImplementation(() => mockClient as any);

       render(<VoiceSessionPage />);

       await waitFor(() => {
         expect(screen.getByText(/connection error/i)).toBeInTheDocument();
         expect(screen.getByText(/retry connection/i)).toBeInTheDocument();
       });
     });
   });
   ```

2. **Mute Toggle Test:**
   ```typescript
   it('toggles mute on button click', async () => {
     const mockClient = {
       connect: vi.fn().mockResolvedValue(undefined),
       on: vi.fn((event, handler) => {
         if (event === 'connected') handler();
       }),
       disconnect: vi.fn(),
       enableMic: vi.fn(),
       disableMic: vi.fn()
     };

     vi.mocked(RTVIClient).mockImplementation(() => mockClient as any);

     render(<VoiceSessionPage />);

     await waitFor(() => {
       expect(screen.getByText(/connected/i)).toBeInTheDocument();
     });

     const muteButton = screen.getByRole('button', { name: /mute/i });
     
     fireEvent.click(muteButton);
     await waitFor(() => {
       expect(mockClient.disableMic).toHaveBeenCalled();
       expect(screen.getByText(/unmute/i)).toBeInTheDocument();
     });

     fireEvent.click(muteButton);
     await waitFor(() => {
       expect(mockClient.enableMic).toHaveBeenCalled();
     });
   });
   ```

3. **End Session Test:**
   ```typescript
   it('ends session and navigates to dashboard', async () => {
     const mockClient = {
       connect: vi.fn().mockResolvedValue(undefined),
       on: vi.fn((event, handler) => {
         if (event === 'connected') handler();
       }),
       disconnect: vi.fn()
     };

     const mockPush = vi.fn();
     vi.mocked(useRouter).mockReturnValue({ push: mockPush } as any);
     vi.mocked(RTVIClient).mockImplementation(() => mockClient as any);

     render(<VoiceSessionPage />);

     await waitFor(() => {
       expect(screen.getByText(/connected/i)).toBeInTheDocument();
     });

     const endButton = screen.getByRole('button', { name: /end session/i });
     fireEvent.click(endButton);

     // Confirm in dialog
     const confirmButton = screen.getByText(/end session/i, { selector: 'button' });
     fireEvent.click(confirmButton);

     await waitFor(() => {
       expect(mockClient.disconnect).toHaveBeenCalled();
       expect(mockPush).toHaveBeenCalledWith('/dashboard');
     });
   });
   ```

4. **E2E Voice Session Test:**
   ```typescript
   import { test, expect } from '@playwright/test';

   test.describe('Voice Session', () => {
     test('connects to voice session successfully', async ({ page, context }) => {
       // Login
       await page.goto('/login');
       await page.fill('input[name="username"]', 'testuser');
       await page.fill('input[name="password"]', 'testpass');
       await page.click('button[type="submit"]');

       // Grant microphone permission
       await context.grantPermissions(['microphone']);

       // Start voice call
       await page.goto('/dashboard');
       const healthCard = page.locator('text=Health Counselor').locator('..');
       await healthCard.locator('button:has-text("Voice Call")').click();

       // Wait for voice session page
       await page.waitForURL(/\/voice-session\?/);

       // Should show connecting state
       await expect(page.locator('text=Connecting')).toBeVisible();

       // Should eventually show connected
       await expect(page.locator('text=Connected')).toBeVisible({ timeout: 15000 });

       // Mute button should be enabled
       const muteButton = page.locator('button:has-text("Mute")');
       await expect(muteButton).toBeEnabled();

       // End session
       await page.click('button:has-text("End Session")');
       await page.click('button:has-text("End Session")', { force: true }); // Confirm dialog

       // Should return to dashboard
       await page.waitForURL('/dashboard');
     });
   });
   ```

5. **Manual Testing Checklist:**
   - [ ] Voice session page loads with room credentials
   - [ ] Browser requests microphone permission
   - [ ] Connection status shows "Connecting..." then "Connected"
   - [ ] User can hear bot greeting
   - [ ] User voice transmitted to bot
   - [ ] Mute button toggles microphone
   - [ ] Microphone icon shows muted state
   - [ ] End session button shows confirmation dialog
   - [ ] End session disconnects and navigates to dashboard
   - [ ] Connection error shows retry button
   - [ ] Permission denied shows helpful error message
   - [ ] Session ID displayed for support reference
   - [ ] Crisis hotline info visible

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-12-20 | 1.0 | Initial story creation | Sarah (PO) |
