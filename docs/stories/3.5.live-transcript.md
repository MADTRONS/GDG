# Story 3.5: Live Transcript Display

**Epic:** Epic 3 - Voice Calling Integration  
**Status:** Draft  
**Created:** December 20, 2025  
**Last Updated:** December 20, 2025

---

## Story

**As a** student user,  
**I want** to see a live transcript of my conversation with the counselor bot,  
**so that** I can follow along visually and refer back to what was said.

---

## Acceptance Criteria

1. Voice session view displays transcript panel showing conversation history in chronological order.
2. RTVIClient "userTranscript" event listener captures student's speech as text and appends to transcript with "You:" label.
3. RTVIClient "botTranscript" event listener captures counselor's responses as text and appends to transcript with "Counselor:" label.
4. Transcript auto-scrolls to bottom as new messages arrive (with option to pause auto-scroll if user scrolls up manually).
5. Each transcript entry includes timestamp (e.g., "2:34 PM").
6. Transcript text is readable with sufficient font size (16px+) and contrast ratio (4.5:1 minimum for WCAG AA).
7. Transcript panel is responsive: side panel on desktop (768px+), bottom panel or overlay on mobile (<768px).
8. Transcript entries stored in state for session logging (Story 3.7).
9. Unit tests verify transcript updates on events.

---

## Tasks / Subtasks

- [ ] Create TranscriptPanel component (AC: 1, 7)
  - [ ] Design responsive layout (side panel desktop, bottom mobile)
  - [ ] Use shadcn/ui Card component for styling
  - [ ] Add header with title "Conversation Transcript"
  - [ ] Create scrollable message container
  - [ ] Style for light/dark mode
  
- [ ] Create TranscriptMessage component (AC: 5, 6)
  - [ ] Display speaker label (You/Counselor)
  - [ ] Display timestamp
  - [ ] Display message text
  - [ ] Apply different styling for user vs counselor messages
  - [ ] Ensure 16px+ font size
  - [ ] Verify 4.5:1 contrast ratio
  
- [ ] Add transcript state management (AC: 2, 3, 8)
  - [ ] Create transcript state array
  - [ ] Define TranscriptEntry interface
  - [ ] Implement addTranscriptEntry function
  - [ ] Store entries with timestamp, speaker, text
  
- [ ] Implement userTranscript event listener (AC: 2)
  - [ ] Listen to RTVIClient "userTranscript" or "user-transcript" event
  - [ ] Extract transcribed text from event
  - [ ] Add entry with speaker="user"
  - [ ] Update transcript state
  
- [ ] Implement botTranscript event listener (AC: 3)
  - [ ] Listen to RTVIClient "botTranscript" or "bot-transcript" event
  - [ ] Extract bot response text
  - [ ] Add entry with speaker="bot"
  - [ ] Update transcript state
  
- [ ] Implement auto-scroll functionality (AC: 4)
  - [ ] Scroll to bottom when new message added
  - [ ] Detect user manual scroll
  - [ ] Pause auto-scroll when user scrolls up
  - [ ] Resume auto-scroll when user scrolls to bottom
  - [ ] Add visual indicator for paused auto-scroll
  
- [ ] Ensure accessibility (AC: 6, 9)
  - [ ] Add ARIA labels to transcript container
  - [ ] Ensure keyboard navigation works
  - [ ] Test with screen readers
  - [ ] Verify color contrast meets WCAG AA
  
- [ ] Make transcript responsive (AC: 7)
  - [ ] Desktop: side panel layout (min-width: 768px)
  - [ ] Mobile: bottom panel or full-width overlay
  - [ ] Test on various screen sizes
  - [ ] Ensure transcript readable on mobile
  
- [ ] Write comprehensive tests (AC: 9)
  - [ ] Mock RTVIClient events
  - [ ] Test transcript updates on userTranscript event
  - [ ] Test transcript updates on botTranscript event
  - [ ] Test auto-scroll behavior
  - [ ] Test manual scroll pauses auto-scroll
  - [ ] Test responsive layout breakpoints

---

## Dev Notes

### Architecture Overview (From Architecture Document)

**Transcript Event Flow:**
1. User speaks → Deepgram STT transcribes → RTVIClient emits "userTranscript" event
2. Gemini LLM generates response → Cartesia TTS synthesizes → RTVIClient emits "botTranscript" event
3. Frontend listens to both events and updates transcript UI in real-time
4. Transcript stored in component state for later persistence (Story 3.7)

**Transcript Data Structure:**
```typescript
interface TranscriptEntry {
  id: string;          // Unique identifier
  timestamp: Date;     // When message was spoken
  speaker: 'user' | 'bot';
  text: string;        // Transcribed/generated text
}
```

### TypeScript Interfaces

**types/transcript.ts:**
```typescript
export type SpeakerType = 'user' | 'bot';

export interface TranscriptEntry {
  id: string;
  timestamp: Date;
  speaker: SpeakerType;
  text: string;
}

export interface TranscriptPanelProps {
  entries: TranscriptEntry[];
  autoScroll: boolean;
  onToggleAutoScroll: () => void;
}
```

### TranscriptMessage Component

**components/voice/TranscriptMessage.tsx:**
```typescript
import { format } from 'date-fns';
import { TranscriptEntry } from '@/types/transcript';
import { cn } from '@/lib/utils';

interface TranscriptMessageProps {
  entry: TranscriptEntry;
}

export function TranscriptMessage({ entry }: TranscriptMessageProps) {
  const isUser = entry.speaker === 'user';

  return (
    <div
      className={cn(
        'flex flex-col gap-1 p-3 rounded-lg',
        isUser ? 'bg-primary/10 ml-8' : 'bg-muted mr-8'
      )}
    >
      <div className="flex items-center gap-2 text-sm font-medium">
        <span className={cn(isUser ? 'text-primary' : 'text-foreground')}>
          {isUser ? 'You' : 'Counselor'}
        </span>
        <span className="text-xs text-muted-foreground">
          {format(entry.timestamp, 'h:mm a')}
        </span>
      </div>
      <p className="text-base leading-relaxed">
        {entry.text}
      </p>
    </div>
  );
}
```

### TranscriptPanel Component

**components/voice/TranscriptPanel.tsx:**
```typescript
import { useEffect, useRef, useState } from 'react';
import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';
import { Button } from '@/components/ui/button';
import { ScrollArea } from '@/components/ui/scroll-area';
import { ArrowDown } from 'lucide-react';
import { TranscriptMessage } from './TranscriptMessage';
import { TranscriptEntry } from '@/types/transcript';

interface TranscriptPanelProps {
  entries: TranscriptEntry[];
}

export function TranscriptPanel({ entries }: TranscriptPanelProps) {
  const scrollRef = useRef<HTMLDivElement>(null);
  const [autoScroll, setAutoScroll] = useState(true);
  const [showScrollButton, setShowScrollButton] = useState(false);

  // Auto-scroll to bottom when new entries added
  useEffect(() => {
    if (autoScroll && scrollRef.current) {
      scrollRef.current.scrollTop = scrollRef.current.scrollHeight;
    }
  }, [entries, autoScroll]);

  // Detect user scroll
  const handleScroll = () => {
    if (!scrollRef.current) return;

    const { scrollTop, scrollHeight, clientHeight } = scrollRef.current;
    const isAtBottom = scrollHeight - scrollTop - clientHeight < 50;

    setAutoScroll(isAtBottom);
    setShowScrollButton(!isAtBottom);
  };

  // Scroll to bottom manually
  const scrollToBottom = () => {
    if (scrollRef.current) {
      scrollRef.current.scrollTop = scrollRef.current.scrollHeight;
      setAutoScroll(true);
      setShowScrollButton(false);
    }
  };

  return (
    <Card className="h-full flex flex-col">
      <CardHeader className="pb-3">
        <CardTitle className="text-lg">Conversation Transcript</CardTitle>
      </CardHeader>
      <CardContent className="flex-1 relative p-0">
        <div
          ref={scrollRef}
          onScroll={handleScroll}
          className="h-full overflow-y-auto px-4 pb-4 space-y-3"
          aria-live="polite"
          aria-label="Conversation transcript"
        >
          {entries.length === 0 ? (
            <div className="flex items-center justify-center h-full text-muted-foreground">
              <p>Transcript will appear here as you speak...</p>
            </div>
          ) : (
            entries.map(entry => (
              <TranscriptMessage key={entry.id} entry={entry} />
            ))
          )}
        </div>

        {/* Scroll to bottom button */}
        {showScrollButton && (
          <Button
            onClick={scrollToBottom}
            size="icon"
            variant="secondary"
            className="absolute bottom-4 right-4 rounded-full shadow-lg"
            aria-label="Scroll to latest message"
          >
            <ArrowDown className="h-4 w-4" />
          </Button>
        )}
      </CardContent>
    </Card>
  );
}
```

### Updated Voice Session Page (with Transcript)

**app/voice-session/page.tsx (additions):**
```typescript
import { TranscriptPanel } from '@/components/voice/TranscriptPanel';
import { TranscriptEntry } from '@/types/transcript';
import { v4 as uuidv4 } from 'uuid';

function VoiceSessionContent() {
  // ... existing state ...
  const [transcript, setTranscript] = useState<TranscriptEntry[]>([]);

  // Add transcript entry helper
  const addTranscriptEntry = (speaker: 'user' | 'bot', text: string) => {
    const entry: TranscriptEntry = {
      id: uuidv4(),
      timestamp: new Date(),
      speaker,
      text
    };
    setTranscript(prev => [...prev, entry]);
  };

  // Initialize RTVI Client with transcript listeners
  useEffect(() => {
    if (!roomUrl || !userToken || hasConnected.current) return;

    const initializeClient = async () => {
      try {
        // ... existing initialization ...

        const client = new RTVIClient({ /* ... */ });

        // Existing event listeners
        client.on('connected', () => { /* ... */ });
        client.on('disconnected', () => { /* ... */ });
        client.on('error', () => { /* ... */ });

        // NEW: Transcript event listeners
        client.on('userTranscript', (data: any) => {
          console.log('User transcript:', data);
          if (data.text) {
            addTranscriptEntry('user', data.text);
          }
        });

        client.on('botTranscript', (data: any) => {
          console.log('Bot transcript:', data);
          if (data.text) {
            addTranscriptEntry('bot', data.text);
          }
        });

        // ... rest of initialization ...
      } catch (error) {
        // ... error handling ...
      }
    };

    initializeClient();
  }, [roomUrl, userToken, category, toast]);

  // ... existing render logic ...

  return (
    <div className="container mx-auto min-h-screen p-4">
      {/* Desktop layout: Side-by-side */}
      <div className="hidden md:grid md:grid-cols-[1fr,400px] gap-4 h-[calc(100vh-2rem)]">
        {/* Main session card */}
        <Card className="flex flex-col">
          {/* ... existing session controls ... */}
        </Card>

        {/* Transcript panel */}
        <TranscriptPanel entries={transcript} />
      </div>

      {/* Mobile layout: Stacked */}
      <div className="md:hidden flex flex-col gap-4">
        {/* Session controls */}
        <Card>
          {/* ... existing session controls ... */}
        </Card>

        {/* Transcript panel (fixed height on mobile) */}
        <div className="h-96">
          <TranscriptPanel entries={transcript} />
        </div>
      </div>

      {/* ... existing end session dialog ... */}
    </div>
  );
}
```

### Alternative: Transcript as Toggleable Overlay

For mobile, you could implement a toggleable transcript overlay:

```typescript
const [showTranscript, setShowTranscript] = useState(false);

// Add button to toggle transcript
<Button onClick={() => setShowTranscript(!showTranscript)}>
  {showTranscript ? 'Hide' : 'Show'} Transcript
</Button>

// Render transcript as overlay
{showTranscript && (
  <div className="fixed inset-0 bg-background/95 z-50 p-4">
    <div className="flex justify-between items-center mb-4">
      <h2 className="text-xl font-bold">Transcript</h2>
      <Button onClick={() => setShowTranscript(false)}>
        Close
      </Button>
    </div>
    <TranscriptPanel entries={transcript} />
  </div>
)}
```

### Handling Interim Transcripts

Deepgram provides interim (partial) transcripts before final results. You may want to show these in real-time:

```typescript
const [interimUserText, setInterimUserText] = useState('');

client.on('userTranscriptInterim', (data: any) => {
  // Show interim text without adding to transcript
  setInterimUserText(data.text);
});

client.on('userTranscript', (data: any) => {
  // Final transcript - add to history and clear interim
  addTranscriptEntry('user', data.text);
  setInterimUserText('');
});

// In TranscriptPanel, show interim text in italics
{interimUserText && (
  <div className="text-muted-foreground italic">You: {interimUserText}</div>
)}
```

### Source Tree Updates

```
packages/frontend/
├── app/
│   └── voice-session/
│       └── page.tsx              # Updated with transcript integration
├── components/
│   └── voice/
│       ├── TranscriptPanel.tsx   # Transcript container component
│       └── TranscriptMessage.tsx # Individual message component
└── types/
    └── transcript.ts             # Transcript types
```

---

## Testing

### Testing Standards

**Test Locations:**
- Component tests: `__tests__/components/voice/TranscriptPanel.test.tsx`
- Component tests: `__tests__/components/voice/TranscriptMessage.test.tsx`
- Integration tests: `e2e/voice-transcript.spec.ts`

**Testing Requirements:**

1. **Transcript Update Tests:**
   ```typescript
   import { render, screen } from '@testing-library/react';
   import { TranscriptPanel } from '@/components/voice/TranscriptPanel';
   import { TranscriptEntry } from '@/types/transcript';

   describe('TranscriptPanel', () => {
     const mockEntries: TranscriptEntry[] = [
       {
         id: '1',
         timestamp: new Date('2025-01-01T14:30:00'),
         speaker: 'user',
         text: 'Hello, I need help with stress.'
       },
       {
         id: '2',
         timestamp: new Date('2025-01-01T14:30:05'),
         speaker: 'bot',
         text: 'I\'m here to listen. Tell me what\'s been on your mind.'
       }
     ];

     it('renders transcript entries', () => {
       render(<TranscriptPanel entries={mockEntries} />);

       expect(screen.getByText('You')).toBeInTheDocument();
       expect(screen.getByText('Hello, I need help with stress.')).toBeInTheDocument();
       expect(screen.getByText('Counselor')).toBeInTheDocument();
       expect(screen.getByText(/I'm here to listen/)).toBeInTheDocument();
     });

     it('shows empty state when no entries', () => {
       render(<TranscriptPanel entries={[]} />);

       expect(screen.getByText(/transcript will appear here/i)).toBeInTheDocument();
     });

     it('formats timestamps correctly', () => {
       render(<TranscriptPanel entries={mockEntries} />);

       // Timestamps should be formatted as "h:mm a" (e.g., "2:30 PM")
       expect(screen.getByText('2:30 PM')).toBeInTheDocument();
       expect(screen.getByText('2:30 PM')).toBeInTheDocument();
     });
   });
   ```

2. **Auto-Scroll Tests:**
   ```typescript
   it('auto-scrolls to bottom when new entry added', async () => {
     const { rerender } = render(<TranscriptPanel entries={[mockEntries[0]]} />);

     const scrollContainer = screen.getByLabelText('Conversation transcript');
     const initialScrollTop = scrollContainer.scrollTop;

     // Add new entry
     rerender(<TranscriptPanel entries={mockEntries} />);

     await waitFor(() => {
       expect(scrollContainer.scrollTop).toBeGreaterThan(initialScrollTop);
     });
   });

   it('shows scroll to bottom button when user scrolls up', () => {
     render(<TranscriptPanel entries={mockEntries} />);

     const scrollContainer = screen.getByLabelText('Conversation transcript');
     
     // Simulate user scroll up
     fireEvent.scroll(scrollContainer, { target: { scrollTop: 0 } });

     expect(screen.getByLabelText('Scroll to latest message')).toBeInTheDocument();
   });
   ```

3. **RTVIClient Event Tests:**
   ```typescript
   it('adds user transcript entry on userTranscript event', async () => {
     const mockClient = {
       on: vi.fn(),
       connect: vi.fn(),
       disconnect: vi.fn()
     };

     vi.mocked(RTVIClient).mockImplementation(() => mockClient as any);

     render(<VoiceSessionPage />);

     // Get the userTranscript event handler
     const userTranscriptHandler = mockClient.on.mock.calls.find(
       call => call[0] === 'userTranscript'
     )?.[1];

     // Trigger event
     userTranscriptHandler({ text: 'Test user message' });

     await waitFor(() => {
       expect(screen.getByText('Test user message')).toBeInTheDocument();
     });
   });

   it('adds bot transcript entry on botTranscript event', async () => {
     // Similar test for bot transcript
   });
   ```

4. **Accessibility Tests:**
   ```typescript
   it('has accessible transcript container', () => {
     render(<TranscriptPanel entries={mockEntries} />);

     const container = screen.getByLabelText('Conversation transcript');
     expect(container).toHaveAttribute('aria-live', 'polite');
   });

   it('meets contrast ratio requirements', () => {
     // Use @testing-library/jest-axe for automated accessibility testing
     const { container } = render(<TranscriptPanel entries={mockEntries} />);
     
     const results = await axe(container);
     expect(results).toHaveNoViolations();
   });
   ```

5. **Responsive Layout Tests:**
   ```typescript
   it('renders side panel on desktop', () => {
     // Mock window.matchMedia for desktop
     window.matchMedia = vi.fn().mockImplementation(query => ({
       matches: query.includes('min-width: 768px'),
       media: query,
       addEventListener: vi.fn(),
       removeEventListener: vi.fn()
     }));

     render(<VoiceSessionPage />);

     // Desktop layout should have grid with transcript panel
     expect(screen.getByText('Conversation Transcript')).toBeInTheDocument();
   });
   ```

6. **Manual Testing Checklist:**
   - [ ] Transcript panel visible on voice session page
   - [ ] User speech appears in transcript with "You" label
   - [ ] Bot responses appear with "Counselor" label
   - [ ] Timestamps show correctly formatted time
   - [ ] Transcript auto-scrolls to latest message
   - [ ] Manual scroll up pauses auto-scroll
   - [ ] "Scroll to bottom" button appears when scrolled up
   - [ ] Clicking button scrolls to bottom and resumes auto-scroll
   - [ ] Desktop layout shows side-by-side transcript
   - [ ] Mobile layout shows transcript below session controls
   - [ ] Text size is 16px or larger
   - [ ] Color contrast meets WCAG AA (4.5:1)
   - [ ] Screen reader announces new transcript entries
   - [ ] Empty state shown when no messages

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-12-20 | 1.0 | Initial story creation | Sarah (PO) |
