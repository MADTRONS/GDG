# Story 4.2: Beyond Presence Avatar Configuration

**Epic:** Epic 4 - Video Calling Integration  
**Status:** Draft  
**Created:** December 20, 2025  
**Last Updated:** December 20, 2025

---

## Story

**As a** backend developer,  
**I want** Beyond Presence avatars configured with counselor personas and visual styles,  
**so that** each counselor category has a distinct, appropriate avatar appearance.

---

## Acceptance Criteria

1. Avatar IDs pre-configured in Beyond Presence dashboard for each counselor category (Health, Career, Academic, Financial Aid, Social Wellness, Personal Development).
2. Avatar configuration includes: appearance (professional, approachable), emotional expression ranges (supportive, concerned, encouraging), voice characteristics.
3. System prompts for video sessions match voice calling prompts from Story 3.2 but optimized for visual context (e.g., "maintain supportive facial expressions").
4. Avatar agent initialization in backend loads correct avatar_id based on counselor_category parameter.
5. Agent configured with background audio player for typing sounds or thinking indicators during processing pauses.
6. Logs confirm correct avatar loaded for each video session.
7. Avatar agent script (video_agent.py) created using LiveKit Agents SDK and Beyond Presence integration.
8. Agent connects to LiveKit room and renders avatar video stream.
9. Unit tests verify avatar initialization and configuration loading.

---

## Tasks / Subtasks

- [ ] Set up Beyond Presence avatars (AC: 1, 2)
  - [ ] Create Beyond Presence account/project
  - [ ] Configure 6 avatar identities (one per category)
  - [ ] Customize avatar appearances for professional counseling
  - [ ] Set emotional expression ranges
  - [ ] Configure voice characteristics (warm, empathetic)
  - [ ] Document avatar IDs for each category
  
- [ ] Update system prompts for video (AC: 3)
  - [ ] Copy prompts from Story 3.2
  - [ ] Add visual cues: "maintain eye contact", "use supportive facial expressions"
  - [ ] Add instructions for nodding and active listening gestures
  - [ ] Update seed data script
  
- [ ] Create avatar agent script (AC: 7, 8)
  - [ ] Create avatar_agent/video_agent.py
  - [ ] Import LiveKit Agents SDK
  - [ ] Import Beyond Presence integration
  - [ ] Initialize agent with avatar_id from env var
  - [ ] Connect to LiveKit room
  - [ ] Start avatar video stream
  
- [ ] Implement avatar configuration loading (AC: 4, 6)
  - [ ] Load AVATAR_ID from environment
  - [ ] Load COUNSELOR_CATEGORY for logging
  - [ ] Load SYSTEM_PROMPT for AI model
  - [ ] Log avatar initialization details
  - [ ] Validate all required env vars present
  
- [ ] Configure OpenAI Realtime Model (AC: 7)
  - [ ] Initialize OpenAI Realtime API client
  - [ ] Set system instructions from prompt
  - [ ] Configure low-latency settings
  - [ ] Set temperature to 0.7
  - [ ] Configure function calling if needed
  
- [ ] Add background audio features (AC: 5)
  - [ ] Configure subtle background sounds
  - [ ] Add thinking indicators during pauses
  - [ ] Ensure audio doesn't interfere with speech
  
- [ ] Implement conversation loop (AC: 8)
  - [ ] Listen to participant audio
  - [ ] Send audio to OpenAI Realtime Model
  - [ ] Receive response text and audio
  - [ ] Sync avatar lip movements with audio
  - [ ] Handle turn-taking and interruptions
  
- [ ] Implement graceful shutdown
  - [ ] Listen for room disconnect events
  - [ ] Clean up avatar resources
  - [ ] Close LiveKit connection
  - [ ] Log session end
  - [ ] Exit process cleanly
  
- [ ] Write comprehensive tests (AC: 9)
  - [ ] Unit test agent initialization
  - [ ] Test avatar configuration loading
  - [ ] Test system prompt loading
  - [ ] Integration test with mock LiveKit room
  - [ ] Test conversation flow
  - [ ] Test graceful shutdown

---

## Dev Notes

### Architecture Overview (From Architecture Document)

**Beyond Presence Avatar System:**
- 3D avatars with realistic facial expressions and lip-sync
- Powered by LiveKit Agents SDK
- Integrates with OpenAI Realtime Model for conversational AI
- Reference: https://github.com/ruxakK/ai_avatar_it_support_agent.git

**Conversation Pipeline:**
```
User Audio → LiveKit → OpenAI Realtime Model → Avatar (with lip-sync) → LiveKit → User
```

**Avatar Customization Strategy:**
- Each counselor category has unique avatar appearance
- Avatars designed to be professional, approachable, diverse
- Expressions calibrated for supportive counseling interactions
- Voice characteristics match counselor role (calm, encouraging)

### Avatar Configuration Mapping

**Avatar IDs by Category (configure in Beyond Presence dashboard):**

```python
AVATAR_CONFIG = {
    "Health Counselor": {
        "avatar_id": "avatar-health-001",
        "appearance": "Warm, professional, mid-30s",
        "voice": "Calm, empathetic, moderate pace",
        "expressions": ["supportive", "concerned", "encouraging", "attentive"]
    },
    "Career Counselor": {
        "avatar_id": "avatar-career-001",
        "appearance": "Confident, business casual, 40s",
        "voice": "Energetic, motivational, clear",
        "expressions": ["encouraging", "thoughtful", "positive", "inspiring"]
    },
    "Academic Counselor": {
        "avatar_id": "avatar-academic-001",
        "appearance": "Approachable, scholarly, 30s",
        "voice": "Patient, explanatory, steady",
        "expressions": ["understanding", "focused", "helpful", "nodding"]
    },
    "Financial Aid Counselor": {
        "avatar_id": "avatar-financial-001",
        "appearance": "Trustworthy, professional, 35+",
        "voice": "Reassuring, clear, informative",
        "expressions": ["reassuring", "explanatory", "friendly", "patient"]
    },
    "Social Wellness Counselor": {
        "avatar_id": "avatar-social-001",
        "appearance": "Friendly, casual, late 20s",
        "voice": "Warm, conversational, upbeat",
        "expressions": ["smiling", "welcoming", "enthusiastic", "relatable"]
    },
    "Personal Development Coach": {
        "avatar_id": "avatar-dev-001",
        "appearance": "Inspiring, modern, 30s",
        "voice": "Empowering, dynamic, forward-thinking",
        "expressions": ["inspiring", "confident", "focused", "motivational"]
    }
}
```

### Enhanced System Prompts for Video

Add visual instructions to prompts from Story 3.2:

```python
VISUAL_INSTRUCTIONS = """

**VISUAL COMMUNICATION GUIDELINES:**
As a video counselor, your non-verbal communication is important:

1. **Eye Contact:** Maintain natural eye contact by looking at the camera. This helps build trust.
2. **Facial Expressions:** Use supportive, warm expressions. Smile when appropriate. Show concern when discussing difficulties.
3. **Active Listening:** Nod occasionally to show you're listening and understanding.
4. **Posture:** Maintain an open, approachable posture. Lean in slightly when the student shares something important.
5. **Gestures:** Use subtle hand gestures to emphasize points, but don't be distracting.
6. **Pacing:** Allow natural pauses for the student to think. Your avatar will show attentive listening during pauses.
7. **Empathy Display:** When the student shares challenges, your expression should reflect understanding and empathy.

Remember: Your visual presence should reinforce the supportive, professional counseling environment.
"""

# Update prompts from Story 3.2
HEALTH_PROMPT_VIDEO = HEALTH_PROMPT + VISUAL_INSTRUCTIONS
CAREER_PROMPT_VIDEO = CAREER_PROMPT + VISUAL_INSTRUCTIONS
# ... etc for all categories
```

### Beyond Presence Avatar Agent Script

**avatar_agent/video_agent.py:**
```python
import asyncio
import os
import sys
from loguru import logger
from livekit import rtc
from livekit.agents import (
    AutoSubscribe,
    JobContext,
    WorkerOptions,
    cli,
    llm,
)
from livekit.plugins import openai, beyond_presence

# Configure logging
logger.remove()
logger.add(sys.stderr, level="INFO")

class VideoAvatarAgent:
    """Beyond Presence avatar agent for video counseling sessions."""
    
    def __init__(self):
        # Load environment variables
        self.room_name = os.getenv("ROOM_NAME")
        self.session_id = os.getenv("SESSION_ID")
        self.avatar_id = os.getenv("AVATAR_ID")
        self.system_prompt = os.getenv("SYSTEM_PROMPT")
        self.counselor_category = os.getenv("COUNSELOR_CATEGORY", "General")
        
        # Validate required config
        if not all([self.room_name, self.session_id, self.avatar_id, self.system_prompt]):
            raise ValueError("Missing required environment variables")
        
        logger.info(f"Initializing VideoAvatarAgent for session {self.session_id}")
        logger.info(f"Category: {self.counselor_category}")
        logger.info(f"Avatar ID: {self.avatar_id}")
    
    async def entrypoint(self, ctx: JobContext):
        """Main entry point for the agent."""
        
        logger.info(f"Connecting to room: {self.room_name}")
        
        # Connect to LiveKit room
        await ctx.connect(auto_subscribe=AutoSubscribe.AUDIO_ONLY)
        
        # Wait for first participant (student) to join
        participant = await ctx.wait_for_participant()
        logger.info(f"Student participant joined: {participant.identity}")
        
        # Initialize OpenAI Realtime Model
        model = openai.realtime.RealtimeModel(
            instructions=self.system_prompt,
            voice="alloy",  # Can customize per category
            temperature=0.7,
            modalities=["text", "audio"],
        )
        
        # Initialize Beyond Presence avatar
        avatar = beyond_presence.Avatar(
            avatar_id=self.avatar_id,
            api_key=os.getenv("BEYOND_PRESENCE_API_KEY"),
        )
        
        # Create agent assistant with avatar
        assistant = llm.AssistantLLM(
            model=model,
            avatar=avatar,
        )
        
        # Start conversation session
        session = assistant.start_session(
            room=ctx.room,
            participant=participant,
        )
        
        # Greeting
        greeting = self._get_greeting()
        await session.say(greeting)
        
        logger.info("Avatar agent ready and connected")
        
        # Run conversation loop
        await session.wait_for_completion()
        
        logger.info("Session completed")
    
    def _get_greeting(self) -> str:
        """Get category-appropriate greeting."""
        greetings = {
            "Health": "Hi there, I'm here to support you. What's on your mind today?",
            "Career": "Hello! I'm excited to help you explore your career path. What brings you in?",
            "Academic": "Hi! I'm here to help with your studies. What can I assist you with today?",
            "Financial Aid": "Hello! I'm here to help you navigate financial aid. What questions do you have?",
            "Social Wellness": "Hi! Let's talk about building connections and campus life. What's up?",
            "Personal Development": "Hello! I'm here to support your personal growth journey. What would you like to work on?"
        }
        return greetings.get(self.counselor_category, "Hello! How can I help you today?")


async def main():
    """Entry point for avatar agent process."""
    logger.info("=== VideoAvatarAgent Starting ===")
    
    try:
        agent = VideoAvatarAgent()
        
        # Create worker options
        worker_options = WorkerOptions(
            entrypoint_fnc=agent.entrypoint,
            request_fnc=None,  # Not using request-based workflow
        )
        
        # Run LiveKit agent worker
        await cli.run_app(worker_options)
        
    except KeyboardInterrupt:
        logger.info("Agent interrupted by user")
    except Exception as e:
        logger.error(f"Fatal error: {e}")
        sys.exit(1)
    
    logger.info("=== VideoAvatarAgent Exiting ===")


if __name__ == "__main__":
    asyncio.run(main())
```

### Simpler Implementation (Alternative)

If Beyond Presence SDK is complex, here's a more straightforward approach:

**avatar_agent/video_agent_simple.py:**
```python
import asyncio
import os
from livekit import rtc, api
from openai import AsyncOpenAI
from loguru import logger

class SimpleVideoAgent:
    """Simplified video agent with basic avatar rendering."""
    
    def __init__(self):
        self.livekit_url = os.getenv("LIVEKIT_URL")
        self.api_key = os.getenv("LIVEKIT_API_KEY")
        self.api_secret = os.getenv("LIVEKIT_API_SECRET")
        self.room_name = os.getenv("ROOM_NAME")
        self.system_prompt = os.getenv("SYSTEM_PROMPT")
        
        self.room = None
        self.openai_client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    
    async def connect(self):
        """Connect to LiveKit room."""
        # Generate token for agent
        token = api.AccessToken(self.api_key, self.api_secret)
        token.with_identity("avatar-agent")
        token.with_name("Counselor Avatar")
        token.with_grants(api.VideoGrants(
            room_join=True,
            room=self.room_name,
            can_publish=True,
            can_subscribe=True,
        ))
        
        # Connect to room
        self.room = rtc.Room()
        await self.room.connect(self.livekit_url, token.to_jwt())
        
        logger.info(f"Connected to room: {self.room_name}")
    
    async def start_conversation(self):
        """Start conversation loop."""
        # This is a simplified version
        # Full implementation would handle audio transcription,
        # LLM responses, TTS, and avatar rendering
        
        logger.info("Conversation started")
        
        # Wait for room events
        while True:
            await asyncio.sleep(1)
    
    async def disconnect(self):
        """Disconnect from room."""
        if self.room:
            await self.room.disconnect()
        logger.info("Disconnected from room")


async def main():
    agent = SimpleVideoAgent()
    
    try:
        await agent.connect()
        await agent.start_conversation()
    except KeyboardInterrupt:
        logger.info("Agent interrupted")
    finally:
        await agent.disconnect()


if __name__ == "__main__":
    asyncio.run(main())
```

### Avatar Configuration Database

Optionally, store avatar IDs in database:

**Add to CounselorCategory model:**
```python
class CounselorCategory(Base):
    # ... existing fields ...
    avatar_id = Column(String(100), nullable=True)  # Beyond Presence avatar ID
```

**Migration:**
```python
def upgrade() -> None:
    op.add_column('counselor_categories', sa.Column('avatar_id', sa.String(100), nullable=True))

def downgrade() -> None:
    op.drop_column('counselor_categories', 'avatar_id')
```

### Source Tree Updates

```
packages/backend/
└── avatar_agent/
    ├── video_agent.py            # Full Beyond Presence implementation
    ├── video_agent_simple.py     # Simplified alternative
    └── __init__.py
```

---

## Testing

### Testing Requirements:

1. **Avatar Initialization Test:**
   ```python
   def test_avatar_agent_initialization():
       os.environ.update({
           "ROOM_NAME": "test-room",
           "SESSION_ID": "session-123",
           "AVATAR_ID": "avatar-test",
           "SYSTEM_PROMPT": "Test prompt",
           "COUNSELOR_CATEGORY": "Health"
       })
       
       agent = VideoAvatarAgent()
       
       assert agent.room_name == "test-room"
       assert agent.avatar_id == "avatar-test"
       assert agent.counselor_category == "Health"
   
   def test_missing_env_vars_raises_error():
       with pytest.raises(ValueError, match="Missing required environment variables"):
           agent = VideoAvatarAgent()
   ```

2. **Avatar Configuration Loading Test:**
   ```python
   @pytest.mark.asyncio
   async def test_avatar_loads_correct_config(db_session):
       from app.repositories.counselor_repository import CounselorRepository
       
       repo = CounselorRepository(db_session)
       
       # Create test category with avatar_id
       category = await repo.create({
           "name": "Health Counselor",
           "avatar_id": "avatar-health-001",
           "system_prompt": "Test prompt"
       })
       
       assert category.avatar_id == "avatar-health-001"
   ```

3. **System Prompt Enhancement Test:**
   ```python
   def test_video_prompts_include_visual_instructions():
       assert "eye contact" in HEALTH_PROMPT_VIDEO.lower()
       assert "facial expressions" in CAREER_PROMPT_VIDEO.lower()
       assert "nodding" in ACADEMIC_PROMPT_VIDEO.lower()
   ```

4. **Manual Testing Checklist:**
   - [ ] Avatar agent script runs without errors
   - [ ] Agent connects to LiveKit room
   - [ ] Correct avatar loaded based on category
   - [ ] System prompt includes visual instructions
   - [ ] Avatar video stream appears in room
   - [ ] Avatar responds to audio input
   - [ ] Lip-sync works correctly
   - [ ] Emotional expressions visible
   - [ ] Agent disconnects gracefully
   - [ ] Logs show correct initialization details
   - [ ] All 6 categories have configured avatars
   - [ ] Avatar appearances are professional and appropriate

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-12-20 | 1.0 | Initial story creation | Sarah (PO) |
