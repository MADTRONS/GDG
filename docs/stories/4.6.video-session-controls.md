# Story 4.6: Video Session Transcript and Controls

**Epic:** Epic 4 - Video Calling Integration  
**Status:** Draft  
**Created:** December 20, 2025  
**Last Updated:** December 20, 2025

---

## Story

**As a** student user,  
**I want** to see live transcript and have session controls during video call,  
**so that** I can review conversation and manage the session easily.

---

## Acceptance Criteria

1. Video session UI split into two sections: avatar video (70% width), transcript panel (30% width).
2. Transcript displays in real-time with speaker labels ("You:" for student, "Counselor:" for avatar).
3. Transcript auto-scrolls as new messages arrive, with option to scroll up and pause auto-scroll.
4. Mute button toggles student microphone on/off with visual indicator (red when muted).
5. Volume slider controls avatar audio output (0-100%), with icon showing current level.
6. End session button prominently displayed with confirmation dialog before disconnect.
7. Connection quality indicator shows signal strength (excellent, good, fair, poor) with color coding.
8. If connection quality drops to "poor", display notification suggesting fallback to voice-only.
9. Responsive layout: on mobile (<768px), transcript hidden by default with toggle button.

---

## Tasks / Subtasks

- [ ] Create split layout for video session (AC: 1)
  - [ ] Video section: 70% width, full height
  - [ ] Transcript panel: 30% width, full height
  - [ ] Responsive breakpoints for mobile
  - [ ] Ensure video maintains aspect ratio
  
- [ ] Implement real-time transcript display (AC: 2, 3)
  - [ ] Create Transcript component
  - [ ] Display speaker labels ("You:", "Counselor:")
  - [ ] Style user vs counselor messages differently
  - [ ] Auto-scroll to bottom as messages arrive
  - [ ] Pause auto-scroll when user scrolls up manually
  - [ ] Resume auto-scroll when scrolled to bottom
  
- [ ] Implement mute button (AC: 4)
  - [ ] Toggle microphone track enabled/disabled
  - [ ] Show mic icon when unmuted
  - [ ] Show mic-off icon when muted
  - [ ] Red color indicator when muted
  - [ ] Keyboard shortcut (Space bar to toggle)
  
- [ ] Implement volume control (AC: 5)
  - [ ] Slider component (0-100%)
  - [ ] Control avatar audio track volume
  - [ ] Show volume icon: high (>66%), medium (33-66%), low (<33%)
  - [ ] Mute icon if volume is 0%
  - [ ] Persist volume preference in localStorage
  
- [ ] Implement end session button (AC: 6)
  - [ ] Prominently styled button (destructive variant)
  - [ ] Show confirmation dialog on click
  - [ ] Dialog text: "Are you sure you want to end this session?"
  - [ ] Disconnect from LiveKit room on confirm
  - [ ] Navigate to dashboard
  
- [ ] Implement connection quality indicator (AC: 7, 8)
  - [ ] Monitor LiveKit connection quality events
  - [ ] Display signal icon with quality level
  - [ ] Color coding: green (excellent/good), yellow (fair), red (poor)
  - [ ] Tooltip showing current quality
  - [ ] Show notification if quality drops to "poor"
  - [ ] Offer fallback to voice-only option
  
- [ ] Implement responsive mobile layout (AC: 9)
  - [ ] Hide transcript by default on mobile
  - [ ] Add toggle button to show/hide transcript
  - [ ] Full-width video on mobile
  - [ ] Bottom control bar on mobile
  
- [ ] Add accessibility features
  - [ ] Keyboard shortcuts (mute, end session)
  - [ ] ARIA labels for all controls
  - [ ] Focus indicators
  - [ ] Screen reader announcements
  
- [ ] Write comprehensive tests
  - [ ] Test split layout rendering
  - [ ] Test transcript display and auto-scroll
  - [ ] Test mute functionality
  - [ ] Test volume control
  - [ ] Test end session flow
  - [ ] Test connection quality indicator
  - [ ] Test responsive behavior

---

## Dev Notes

### Architecture Overview

**UI Layout:**
```
+-----------------------------------+
|  Header (category, status)        |
+-----------------------------------+
|               |                   |
|   Avatar      |   Transcript      |
|   Video       |   Panel           |
|   (70%)       |   (30%)           |
|               |                   |
+-----------------------------------+
|  Controls (mute, volume, end)     |
+-----------------------------------+
```

**State Management:**
- LiveKit Room state
- Transcript messages array
- Mute status
- Volume level
- Connection quality
- Auto-scroll enabled

### Enhanced Video Session Page

**app/video-session/page.tsx (updated from Story 4.4):**
```typescript
'use client';

import { useEffect, useState, useRef, Suspense } from 'react';
import { useRouter, useSearchParams } from 'next/navigation';
import { Room, RoomEvent, Track, ConnectionQuality } from 'livekit-client';
import { Button } from '@/components/ui/button';
import { Card } from '@/components/ui/card';
import { Slider } from '@/components/ui/slider';
import { ScrollArea } from '@/components/ui/scroll-area';
import { AlertDialog, AlertDialogAction, AlertDialogCancel, AlertDialogContent, AlertDialogDescription, AlertDialogFooter, AlertDialogHeader, AlertDialogTitle } from '@/components/ui/alert-dialog';
import { 
  PhoneOff, 
  Mic, 
  MicOff, 
  Volume2, 
  VolumeX, 
  Volume1,
  Wifi,
  WifiOff,
  MessageSquare,
  Loader2 
} from 'lucide-react';
import { useToast } from '@/components/ui/use-toast';
import { cn } from '@/lib/utils';

type ConnectionState = 'idle' | 'connecting' | 'connected' | 'waiting_avatar' | 'disconnected' | 'error';
type ConnectionQualityLevel = 'excellent' | 'good' | 'fair' | 'poor';

interface TranscriptMessage {
  speaker: 'user' | 'counselor';
  text: string;
  timestamp: Date;
}

function VideoSessionContent() {
  const searchParams = useSearchParams();
  const router = useRouter();
  const { toast } = useToast();

  // Extract room credentials
  const roomUrl = searchParams.get('room_url');
  const accessToken = searchParams.get('access_token');
  const sessionId = searchParams.get('session_id');
  const category = searchParams.get('category') || 'Counselor';

  // State
  const [connectionState, setConnectionState] = useState<ConnectionState>('idle');
  const [connectionQuality, setConnectionQuality] = useState<ConnectionQualityLevel>('good');
  const [showEndDialog, setShowEndDialog] = useState(false);
  const [isMuted, setIsMuted] = useState(false);
  const [volume, setVolume] = useState<number>(80); // Default 80%
  const [transcript, setTranscript] = useState<TranscriptMessage[]>([]);
  const [autoScroll, setAutoScroll] = useState(true);
  const [showTranscript, setShowTranscript] = useState(true); // For mobile toggle
  const [avatarVideoTrack, setAvatarVideoTrack] = useState<MediaStreamTrack | null>(null);
  const [avatarAudioTrack, setAvatarAudioTrack] = useState<any>(null);

  // Refs
  const roomRef = useRef<Room | null>(null);
  const videoRef = useRef<HTMLVideoElement>(null);
  const transcriptRef = useRef<HTMLDivElement>(null);
  const localAudioTrackRef = useRef<any>(null);

  // Load volume from localStorage
  useEffect(() => {
    const savedVolume = localStorage.getItem('avatar_volume');
    if (savedVolume) {
      setVolume(parseInt(savedVolume));
    }
  }, []);

  // Save volume to localStorage
  useEffect(() => {
    localStorage.setItem('avatar_volume', volume.toString());
  }, [volume]);

  // Apply volume to avatar audio track
  useEffect(() => {
    if (avatarAudioTrack) {
      avatarAudioTrack.setVolume(volume / 100);
    }
  }, [volume, avatarAudioTrack]);

  // Auto-scroll transcript
  useEffect(() => {
    if (autoScroll && transcriptRef.current) {
      transcriptRef.current.scrollTop = transcriptRef.current.scrollHeight;
    }
  }, [transcript, autoScroll]);

  // Handle transcript scroll
  const handleTranscriptScroll = () => {
    if (transcriptRef.current) {
      const { scrollTop, scrollHeight, clientHeight } = transcriptRef.current;
      const isAtBottom = scrollHeight - scrollTop - clientHeight < 10;
      setAutoScroll(isAtBottom);
    }
  };

  // Initialize LiveKit Room
  useEffect(() => {
    if (!roomUrl || !accessToken) return;

    const initializeRoom = async () => {
      setConnectionState('connecting');

      try {
        const room = new Room();

        // Connection quality change handler
        room.on(RoomEvent.ConnectionQualityChanged, (quality: ConnectionQuality) => {
          let qualityLevel: ConnectionQualityLevel;
          switch (quality) {
            case ConnectionQuality.Excellent:
              qualityLevel = 'excellent';
              break;
            case ConnectionQuality.Good:
              qualityLevel = 'good';
              break;
            case ConnectionQuality.Poor:
              qualityLevel = 'poor';
              // Show notification for poor quality
              toast({
                title: "Poor Connection Quality",
                description: "Your connection is unstable. Consider switching to voice-only mode.",
                variant: "destructive"
              });
              break;
            default:
              qualityLevel = 'fair';
          }
          setConnectionQuality(qualityLevel);
        });

        // Track subscribed handler
        room.on(RoomEvent.TrackSubscribed, (track, publication, participant) => {
          if (participant.identity.includes('avatar')) {
            if (track.kind === Track.Kind.Video) {
              setConnectionState('connected');
              setAvatarVideoTrack(track.mediaStreamTrack);
            }
            if (track.kind === Track.Kind.Audio) {
              setAvatarAudioTrack(track);
              track.setVolume(volume / 100);
            }
          }
        });

        // Data received handler (for transcript)
        room.on(RoomEvent.DataReceived, (payload: Uint8Array) => {
          const data = JSON.parse(new TextDecoder().decode(payload));
          if (data.type === 'transcript') {
            setTranscript(prev => [...prev, {
              speaker: data.speaker,
              text: data.text,
              timestamp: new Date()
            }]);
          }
        });

        // Connect to room
        await room.connect(roomUrl, accessToken);
        roomRef.current = room;

        // Store local audio track for mute/unmute
        room.localParticipant.audioTracks.forEach(publication => {
          localAudioTrackRef.current = publication.track;
        });

      } catch (error) {
        console.error('Failed to connect:', error);
        setConnectionState('error');
      }
    };

    initializeRoom();

    return () => {
      if (roomRef.current) {
        roomRef.current.disconnect();
      }
    };
  }, [roomUrl, accessToken, volume, toast]);

  // Attach video track to element
  useEffect(() => {
    if (avatarVideoTrack && videoRef.current) {
      const stream = new MediaStream([avatarVideoTrack]);
      videoRef.current.srcObject = stream;
      videoRef.current.play();
    }
  }, [avatarVideoTrack]);

  // Mute/unmute toggle
  const toggleMute = () => {
    if (localAudioTrackRef.current) {
      if (isMuted) {
        localAudioTrackRef.current.unmute();
      } else {
        localAudioTrackRef.current.mute();
      }
      setIsMuted(!isMuted);
    }
  };

  // Keyboard shortcut for mute (Space bar)
  useEffect(() => {
    const handleKeyPress = (e: KeyboardEvent) => {
      if (e.code === 'Space' && e.target === document.body) {
        e.preventDefault();
        toggleMute();
      }
    };
    window.addEventListener('keydown', handleKeyPress);
    return () => window.removeEventListener('keydown', handleKeyPress);
  }, [isMuted]);

  // End session handler
  const handleEndSession = () => {
    if (roomRef.current) {
      roomRef.current.disconnect();
    }
    toast({
      title: "Session Ended",
      description: "Your video counseling session has ended."
    });
    router.push('/dashboard');
  };

  // Connection quality icon
  const ConnectionQualityIcon = () => {
    const icons: Record<ConnectionQualityLevel, { Icon: any; color: string; label: string }> = {
      excellent: { Icon: Wifi, color: 'text-green-600', label: 'Excellent' },
      good: { Icon: Wifi, color: 'text-green-500', label: 'Good' },
      fair: { Icon: Wifi, color: 'text-yellow-500', label: 'Fair' },
      poor: { Icon: WifiOff, color: 'text-red-600', label: 'Poor' },
    };
    const { Icon, color, label } = icons[connectionQuality];
    return (
      <div className={cn("flex items-center gap-1", color)} title={`Connection: ${label}`}>
        <Icon className="h-4 w-4" />
        <span className="text-xs">{label}</span>
      </div>
    );
  };

  // Volume icon
  const VolumeIcon = () => {
    if (volume === 0) return <VolumeX className="h-4 w-4" />;
    if (volume < 33) return <Volume1 className="h-4 w-4" />;
    return <Volume2 className="h-4 w-4" />;
  };

  return (
    <div className="flex flex-col h-screen bg-black">
      {/* Header */}
      <div className="flex items-center justify-between p-4 bg-gray-900 border-b border-gray-800">
        <div>
          <h1 className="text-lg font-bold text-white">Video Session: {category}</h1>
          <p className="text-xs text-gray-400">Session ID: {sessionId}</p>
        </div>
        <div className="flex items-center gap-4">
          <ConnectionQualityIcon />
          <div className={cn(
            "flex items-center gap-1",
            connectionState === 'connected' ? 'text-green-600' : 'text-yellow-500'
          )}>
            <div className="h-2 w-2 rounded-full bg-current animate-pulse" />
            <span className="text-xs">
              {connectionState === 'connected' ? 'Connected' : 'Connecting...'}
            </span>
          </div>
        </div>
      </div>

      {/* Main Content */}
      <div className="flex flex-1 overflow-hidden">
        {/* Video Section */}
        <div className={cn(
          "flex items-center justify-center bg-gray-900 p-4",
          showTranscript ? "w-[70%]" : "w-full"
        )}>
          {avatarVideoTrack ? (
            <video
              ref={videoRef}
              autoPlay
              playsInline
              className="max-w-full max-h-full object-contain rounded-lg shadow-2xl"
            />
          ) : (
            <div className="flex flex-col items-center gap-4 text-white">
              <Loader2 className="h-16 w-16 animate-spin text-blue-500" />
              <p>Waiting for avatar...</p>
            </div>
          )}
        </div>

        {/* Transcript Panel */}
        {showTranscript && (
          <div className="w-[30%] bg-gray-800 border-l border-gray-700 flex flex-col">
            <div className="p-3 border-b border-gray-700">
              <h2 className="text-sm font-semibold text-white flex items-center gap-2">
                <MessageSquare className="h-4 w-4" />
                Live Transcript
              </h2>
            </div>
            <ScrollArea 
              className="flex-1 p-4"
              ref={transcriptRef}
              onScroll={handleTranscriptScroll}
            >
              <div className="space-y-3">
                {transcript.length === 0 ? (
                  <p className="text-gray-400 text-sm italic">Transcript will appear here...</p>
                ) : (
                  transcript.map((msg, idx) => (
                    <div key={idx} className="text-sm">
                      <div className={cn(
                        "font-semibold mb-1",
                        msg.speaker === 'user' ? 'text-blue-400' : 'text-green-400'
                      )}>
                        {msg.speaker === 'user' ? 'You:' : 'Counselor:'}
                      </div>
                      <div className="text-gray-200">{msg.text}</div>
                    </div>
                  ))
                )}
              </div>
            </ScrollArea>
            {!autoScroll && (
              <div className="p-2 border-t border-gray-700">
                <Button 
                  size="sm" 
                  variant="outline" 
                  onClick={() => setAutoScroll(true)}
                  className="w-full"
                >
                  Scroll to Latest
                </Button>
              </div>
            )}
          </div>
        )}
      </div>

      {/* Control Bar */}
      <div className="p-4 bg-gray-900 border-t border-gray-800">
        <div className="flex items-center justify-between max-w-2xl mx-auto">
          {/* Mute Button */}
          <Button
            onClick={toggleMute}
            variant={isMuted ? "destructive" : "outline"}
            size="lg"
            aria-label={isMuted ? "Unmute" : "Mute"}
          >
            {isMuted ? <MicOff className="h-5 w-5" /> : <Mic className="h-5 w-5" />}
          </Button>

          {/* Volume Control */}
          <div className="flex items-center gap-3 flex-1 mx-8">
            <VolumeIcon />
            <Slider
              value={[volume]}
              onValueChange={(values) => setVolume(values[0])}
              max={100}
              step={1}
              className="flex-1"
              aria-label="Volume"
            />
            <span className="text-xs text-gray-400 w-8">{volume}%</span>
          </div>

          {/* End Session Button */}
          <Button
            onClick={() => setShowEndDialog(true)}
            variant="destructive"
            size="lg"
          >
            <PhoneOff className="mr-2 h-5 w-5" />
            End Session
          </Button>

          {/* Mobile Transcript Toggle */}
          <Button
            onClick={() => setShowTranscript(!showTranscript)}
            variant="outline"
            size="lg"
            className="md:hidden ml-2"
          >
            <MessageSquare className="h-5 w-5" />
          </Button>
        </div>

        <div className="text-xs text-gray-400 text-center mt-3">
          <p>Press Space to {isMuted ? 'unmute' : 'mute'}. If you're in crisis, call 988 immediately.</p>
        </div>
      </div>

      {/* End Session Dialog */}
      <AlertDialog open={showEndDialog} onOpenChange={setShowEndDialog}>
        <AlertDialogContent>
          <AlertDialogHeader>
            <AlertDialogTitle>End Video Session?</AlertDialogTitle>
            <AlertDialogDescription>
              Are you sure you want to end this counseling session? You can always start a new session later.
            </AlertDialogDescription>
          </AlertDialogHeader>
          <AlertDialogFooter>
            <AlertDialogCancel>Stay in Session</AlertDialogCancel>
            <AlertDialogAction onClick={handleEndSession}>
              End Session
            </AlertDialogAction>
          </AlertDialogFooter>
        </AlertDialogContent>
      </AlertDialog>
    </div>
  );
}

export default function VideoSessionPage() {
  return (
    <Suspense fallback={
      <div className="flex items-center justify-center min-h-screen bg-black">
        <Loader2 className="h-8 w-8 animate-spin text-white" />
      </div>
    }>
      <VideoSessionContent />
    </Suspense>
  );
}
```

### Responsive Styles

**app/video-session/styles.css:**
```css
/* Mobile responsive adjustments */
@media (max-width: 768px) {
  .video-section {
    width: 100% !important;
  }
  
  .transcript-panel {
    position: fixed;
    top: 0;
    right: 0;
    bottom: 0;
    width: 80%;
    z-index: 50;
    transform: translateX(100%);
    transition: transform 0.3s ease;
  }
  
  .transcript-panel.show {
    transform: translateX(0);
  }
  
  .control-bar {
    flex-wrap: wrap;
    gap: 0.5rem;
  }
}
```

### Source Tree Updates

```
packages/frontend/
├── app/
│   └── video-session/
│       ├── page.tsx              # Enhanced with transcript & controls
│       └── styles.css            # Responsive styles
└── components/
    └── ui/
        └── slider.tsx            # Volume slider component
```

---

## Testing

### Testing Requirements:

1. **Layout Test:**
   ```typescript
   import { render, screen } from '@testing-library/react';
   import VideoSessionPage from '@/app/video-session/page';

   describe('VideoSessionPage Layout', () => {
     it('renders split layout with video and transcript', () => {
       render(<VideoSessionPage />);
       
       expect(screen.getByText(/live transcript/i)).toBeInTheDocument();
       expect(screen.getByRole('video')).toBeInTheDocument();
     });

     it('applies correct width proportions', () => {
       const { container } = render(<VideoSessionPage />);
       
       const videoSection = container.querySelector('.w-\[70\%\]');
       const transcriptPanel = container.querySelector('.w-\[30\%\]');
       
       expect(videoSection).toBeInTheDocument();
       expect(transcriptPanel).toBeInTheDocument();
     });
   });
   ```

2. **Transcript Test:**
   ```typescript
   it('displays transcript messages with speaker labels', () => {
     render(<VideoSessionPage />);
     
     // Simulate receiving transcript message
     act(() => {
       fireEvent(window, new CustomEvent('transcript', {
         detail: { speaker: 'user', text: 'Hello', timestamp: new Date() }
       }));
     });
     
     expect(screen.getByText('You:')).toBeInTheDocument();
     expect(screen.getByText('Hello')).toBeInTheDocument();
   });

   it('auto-scrolls transcript as messages arrive', async () => {
     const { container } = render(<VideoSessionPage />);
     const transcriptArea = container.querySelector('[ref="transcriptRef"]');
     
     // Add multiple messages
     for (let i = 0; i < 20; i++) {
       act(() => {
         // Add message
       });
     }
     
     await waitFor(() => {
       expect(transcriptArea.scrollTop).toBeGreaterThan(0);
     });
   });
   ```

3. **Controls Test:**
   ```typescript
   it('mute button toggles microphone', () => {
     render(<VideoSessionPage />);
     
     const muteButton = screen.getByLabelText(/mute/i);
     
     fireEvent.click(muteButton);
     expect(muteButton).toHaveAttribute('aria-label', 'Unmute');
     
     fireEvent.click(muteButton);
     expect(muteButton).toHaveAttribute('aria-label', 'Mute');
   });

   it('volume slider adjusts avatar audio', () => {
     render(<VideoSessionPage />);
     
     const volumeSlider = screen.getByLabelText(/volume/i);
     
     fireEvent.change(volumeSlider, { target: { value: '50' } });
     
     expect(screen.getByText('50%')).toBeInTheDocument();
   });
   ```

4. **Manual Testing Checklist:**
   - [ ] Layout shows video (70%) and transcript (30%)
   - [ ] Transcript displays with speaker labels
   - [ ] Transcript auto-scrolls as messages arrive
   - [ ] Can scroll up to read earlier messages
   - [ ] "Scroll to Latest" button appears when scrolled up
   - [ ] Mute button toggles microphone on/off
   - [ ] Mute button turns red when muted
   - [ ] Volume slider controls avatar audio (0-100%)
   - [ ] Volume icon changes based on level
   - [ ] Volume preference persists after page reload
   - [ ] End session button shows confirmation dialog
   - [ ] End session disconnects and navigates to dashboard
   - [ ] Connection quality indicator shows current signal strength
   - [ ] Connection quality changes color (green/yellow/red)
   - [ ] Poor connection shows notification with fallback option
   - [ ] Space bar toggles mute (keyboard shortcut)
   - [ ] Mobile: transcript hidden by default
   - [ ] Mobile: toggle button shows/hides transcript
   - [ ] Mobile: controls fit properly on small screens
   - [ ] Crisis hotline info visible in footer

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-12-20 | 1.0 | Initial story creation | Sarah (PO) |
