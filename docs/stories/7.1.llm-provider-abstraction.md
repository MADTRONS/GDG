# Story 7.1: Universal LLM Provider Abstraction - Single Provider for All Agents

## Status
**Partially Complete** - Foundation Ready, Integration Pending

---

## Story

**As a** Platform Administrator,  
**I want** to configure one LLM provider (Groq or Gemini) that powers all counselor agents across the entire system,  
**so that** I can easily switch between providers by changing one configuration setting without modifying any code.

---

## Acceptance Criteria

### Functional Requirements

1. Create abstract base class `LLMProvider` with method: `generate(prompt: str, system_message: str, temperature: float, max_tokens: int) -> LLMResponse`
2. `LLMResponse` dataclass includes: `content: str`, `provider_name: str`, `tokens_used: int`, `latency_ms: float`
3. Implement `GroqAdapter` using official `groq` Python SDK
4. Implement `GeminiAdapter` using official `google-generativeai` Python SDK
5. Create `ProviderFactory` that reads `LLM_PROVIDER` environment variable and returns single provider instance for entire system

### Configuration - Single Provider

6. Environment variable `LLM_PROVIDER` accepts values: `"groq"` or `"gemini"` (default: `"gemini"`)
7. Environment variable `GROQ_API_KEY` for Groq configuration
8. Environment variable `GEMINI_API_KEY` for Gemini configuration
9. System uses ONLY the provider specified in `LLM_PROVIDER` across all counselor agents

### Universal Integration - All Counselor Agents

10. **All 6 counselor categories** (Health, Career, Academic, Financial, Social, Personal Development) use the same provider instance
11. Works with **PipeCat voice sessions** - provider generates text responses for all voice calls
12. Works with **Beyond Presence video sessions** - provider generates text responses for all video calls
13. Works with **crisis detection system** - same provider used for keyword detection
14. All counselor agents can run **concurrently** using the same provider without conflicts

### Switching Providers

15. Changing `LLM_PROVIDER` from `"gemini"` to `"groq"` switches entire system without code changes
16. System logs which provider is active on startup
17. Invalid provider name falls back to default (Gemini) with warning log

### Quality Requirements

18. Unit tests for both Groq and Gemini adapters with mocked SDK calls
19. Integration test: All 6 counselor categories generate responses successfully with Groq
20. Integration test: All 6 counselor categories generate responses successfully with Gemini
21. Concurrent session test: 10+ simultaneous conversations using same provider (no resource conflicts)
22. Provider abstraction adds <50ms latency overhead

---

## Tasks / Subtasks

### Phase 1: Create Abstraction Layer
- [x] **Task 1: Define provider interface** (AC: 1, 2)
  - [x] Create `backend/providers/base.py` with abstract `LLMProvider` class
  - [x] Define `generate()` method signature
  - [x] Create `LLMResponse` dataclass with required fields
  - [x] Create exception classes: `ProviderError`, `RateLimitError`, `InvalidKeyError`, `TimeoutError`

### Phase 2: Implement Providers
- [x] **Task 2: Implement Groq adapter** (AC: 3)
  - [x] Install `groq` SDK: `pip install groq`
  - [x] Create `backend/providers/groq_adapter.py`
  - [x] Implement `GroqAdapter.generate()` method
  - [x] Normalize Groq response to `LLMResponse` format
  - [x] Handle errors: rate limits, timeouts, invalid keys
  - [x] Unit tests with mocked Groq SDK

- [x] **Task 3: Implement Gemini adapter** (AC: 4)
  - [x] Install `google-generativeai` SDK
  - [x] Create `backend/providers/gemini_adapter.py`
  - [x] Implement `GeminiAdapter.generate()` method
  - [x] Normalize Gemini response to `LLMResponse` format
  - [x] Handle errors: rate limits, timeouts, invalid keys, safety filters
  - [x] Unit tests with mocked Gemini SDK

### Phase 3: Create Factory
- [x] **Task 4: Build ProviderFactory** (AC: 5, 6-9, 16-17)
  - [x] Create `backend/providers/factory.py`
  - [x] Implement `get_provider()` method reading `LLM_PROVIDER` env var
  - [x] Support "groq" and "gemini" values
  - [x] Default to "gemini" if not specified or invalid
  - [x] Log warning for invalid provider names
  - [x] Log active provider on startup
  - [x] Unit tests for factory logic
  - [ ] Implement `get_provider()` method reading `LLM_PROVIDER` env var
  - [ ] Support "groq" and "gemini" values
  - [ ] Default to "gemini" if not specified or invalid
  - [ ] Log warning for invalid provider names
  - [ ] Log active provider on startup
  - [ ] Unit tests for factory logic

### Phase 4: Integrate All Counselor Agents
- [ ] **Task 5: Refactor Health Counselor** (AC: 10)
  - [ ] Replace direct LLM SDK calls with `ProviderFactory.get_provider().generate()`
  - [ ] Maintain existing system prompts
  - [ ] Test with both Groq and Gemini

- [ ] **Task 6: Refactor Career Counselor** (AC: 10)
  - [ ] Replace direct LLM SDK calls with provider abstraction
  - [ ] Test with both providers

- [ ] **Task 7: Refactor Academic Counselor** (AC: 10)
  - [ ] Replace direct LLM SDK calls with provider abstraction
  - [ ] Test with both providers

- [ ] **Task 8: Refactor Financial Counselor** (AC: 10)
  - [ ] Replace direct LLM SDK calls with provider abstraction
  - [ ] Test with both providers

- [ ] **Task 9: Refactor Social Counselor** (AC: 10)
  - [ ] Replace direct LLM SDK calls with provider abstraction
  - [ ] Test with both providers

- [ ] **Task 10: Refactor Personal Development Counselor** (AC: 10)
  - [ ] Replace direct LLM SDK calls with provider abstraction
  - [ ] Test with both providers

### Phase 5: Framework Integration
- [ ] **Task 11: Verify PipeCat voice integration** (AC: 11)
  - [ ] Test voice sessions with Groq provider
  - [ ] Test voice sessions with Gemini provider
  - [ ] Verify Deepgram STT  Provider  Cartesia TTS flow

- [ ] **Task 12: Verify Beyond Presence avatar integration** (AC: 12)
  - [ ] Test video sessions with Groq provider
  - [ ] Test video sessions with Gemini provider
  - [ ] Verify avatar lip-sync works with both providers

- [ ] **Task 13: Verify crisis detection** (AC: 13)
  - [ ] Test crisis keyword detection with Groq
  - [ ] Test crisis keyword detection with Gemini

### Phase 6: Testing & Validation
- [ ] **Task 14: Comprehensive integration testing** (AC: 19-20)
  - [ ] Set `LLM_PROVIDER=groq`: Test all 6 counselor categories
  - [ ] Set `LLM_PROVIDER=gemini`: Test all 6 counselor categories
  - [ ] Verify responses are appropriate for each counselor type

- [ ] **Task 15: Concurrent session testing** (AC: 14, 21)
  - [ ] Simulate 10+ simultaneous counseling sessions
  - [ ] Verify no resource conflicts or deadlocks
  - [ ] Test with both Groq and Gemini

- [ ] **Task 16: Performance benchmarking** (AC: 22)
  - [ ] Measure baseline latency (direct SDK calls)
  - [ ] Measure abstraction layer latency
  - [ ] Confirm <50ms overhead

- [ ] **Task 17: Provider switching validation** (AC: 15)
  - [ ] Start system with `LLM_PROVIDER=gemini`
  - [ ] Generate responses, verify Gemini is used
  - [ ] Change to `LLM_PROVIDER=groq`, restart
  - [ ] Verify Groq is now used across all counselors

### Phase 7: Documentation
- [ ] **Task 18: Create documentation**
  - [ ] Configuration guide: How to set `LLM_PROVIDER` env var
  - [ ] Provider switching guide: Change env var + restart
  - [ ] Troubleshooting: Invalid API keys, rate limits
  - [ ] Developer guide: How to add 3rd provider (e.g., Claude)

---

## Dev Notes

### Story Context

**Existing System Integration:**
- **Integrates with:** All counselor category agents (Health, Career, Academic, Financial, Social, Personal Development) 
- **Technology:** FastAPI (Python 3.11+), PipeCat voice framework, Beyond Presence avatar system
- **Current state:** System likely uses OpenAI directly; needs abstraction to support Groq and Gemini
- **Touch points:** All counselor conversation generation, voice sessions, video sessions, crisis detection

**Simplified Architecture:** One provider for entire platform, configured via single environment variable.

### Architecture Implementation

**Simplified Architecture Pattern:**

``python
# backend/providers/config.py
LLM_PROVIDER = os.getenv("LLM_PROVIDER", "gemini")  # "groq" or "gemini"
GROQ_API_KEY = os.getenv("GROQ_API_KEY")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

# backend/providers/factory.py
class ProviderFactory:
    @staticmethod
    def get_provider() -> LLMProvider:
        """Returns single provider instance for entire system"""
        provider_name = os.getenv("LLM_PROVIDER", "gemini").lower()
        
        if provider_name == "groq":
            return GroqAdapter(api_key=os.getenv("GROQ_API_KEY"))
        elif provider_name == "gemini":
            return GeminiAdapter(api_key=os.getenv("GEMINI_API_KEY"))
        else:
            logger.warning(f"Unknown provider {provider_name}, using gemini")
            return GeminiAdapter(api_key=os.getenv("GEMINI_API_KEY"))
``

**Usage Pattern - All Counselors:**

``python
# Every counselor agent uses same pattern:
from backend.providers.factory import ProviderFactory

# Get the single provider instance for entire system
provider = ProviderFactory.get_provider()

# Generate response (same for Health, Career, Academic, etc.)
response = provider.generate(
    prompt=student_message,
    system_message=counselor_system_prompt,
    temperature=0.7,
    max_tokens=500
)
``

### Integration Points

**Framework Integration:**
- **All counselor categories** import `ProviderFactory.get_provider()` instead of direct SDK calls
- **PipeCat voice:** Provider response  Cartesia TTS  Daily.co WebRTC
- **Beyond Presence avatar:** Provider response  Avatar lip-sync  LiveKit WebRTC
- **Crisis detection:** Same provider used for analyzing conversation content

### Environment Configuration

**Environment Variables (.env file):**
``bash
# Choose ONE provider for entire system
LLM_PROVIDER=gemini  # or "groq"

# Provide both API keys (only active one is used)
GROQ_API_KEY=gsk_your_groq_key_here
GEMINI_API_KEY=your_gemini_key_here
``

### Provider Details

**Provider SDKs:**
``bash
# Install both SDKs
pip install groq google-generativeai
``

**Provider Differences to Handle:**
- **Groq:** Fast inference (low latency), uses OpenAI-compatible API format
- **Gemini:** Google's model, has safety filters, different API format
- Abstraction layer normalizes both into same response format

### Critical Integration Points

1. All counselor category routers/services
2. PipeCat bot configuration (voice)
3. Beyond Presence avatar integration (video)
4. Crisis detection keyword analyzer
5. Session logging (track which provider was used)

### Error Handling Strategy

- Both providers can hit rate limits  return `RateLimitError`
- Both can timeout  return `TimeoutError`
- Invalid API keys  return `InvalidKeyError` on first request
- Unified error handling allows counselor code to handle errors generically

### Performance Considerations

- Provider SDK connection pooling: Reuse HTTP connections where possible
- Lazy initialization: Don't instantiate provider until first request
- Concurrent requests: Ensure thread-safety for multiple counselor sessions using same provider
- Target: <50ms abstraction overhead per AC 22

### Key Constraints

- ONE provider active at a time for entire system
- Switching providers requires environment variable change + restart
- Both API keys can be present, but only configured provider is used
- All counselor agents must work identically regardless of provider choice

---

## Testing

### Testing Standards

**Test Framework:** pytest with pytest-asyncio for async tests  
**Test Location:** `packages/backend/tests/providers/`  
**Coverage Target:** 90%+ for provider adapters and factory  
**Mocking:** unittest.mock for SDK calls in unit tests

### Test Structure

``
packages/backend/tests/providers/
 test_groq_adapter.py           # Unit tests for Groq
 test_gemini_adapter.py         # Unit tests for Gemini
 test_factory.py                # Factory env var logic
 test_all_counselors_groq.py    # Integration: 6 counselors with Groq
 test_all_counselors_gemini.py  # Integration: 6 counselors with Gemini
 test_concurrent_sessions.py    # Load test
 test_provider_switching.py     # Switch between providers
``

### Integration Test Pattern

``python
# test_all_counselors_groq.py
@pytest.mark.integration
def test_all_counselors_with_groq():
    os.environ["LLM_PROVIDER"] = "groq"
    
    counselor_categories = [
        "Health", "Career", "Academic", 
        "Financial", "Social", "PersonalDevelopment"
    ]
    
    for category in counselor_categories:
        provider = ProviderFactory.get_provider()
        response = provider.generate(
            prompt="Hello, I need help",
            system_message=f"You are a {category} counselor",
            temperature=0.7,
            max_tokens=100
        )
        assert response.content
        assert response.provider_name == "groq"
``

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-12-20 | 1.0 | Initial story draft | Sarah (PO) |
| 2025-12-20 | 2.0 | All counselors + all frameworks integration | Sarah (PO) |
| 2025-12-20 | 3.0 | Simplified: ONE provider for entire system (Groq OR Gemini) | Sarah (PO) |

---

## Dev Agent Record

### Agent Model Used
- Claude Sonnet 4.5

### Implementation Summary

**Phases 1-3 Completed:**
- âœ… Created abstract base class `LLMProvider` with `generate()` method and `LLMResponse` dataclass
- âœ… Implemented `GroqAdapter` using official Groq Python SDK with full error handling
- âœ… Implemented `GeminiAdapter` using official Google Generative AI SDK with safety filter handling  
- âœ… Created `ProviderFactory` with singleton pattern that reads `LLM_PROVIDER` env var
- âœ… Added LLM configuration to `app/config.py` (llm_provider, groq_api_key, gemini_api_key)
- âœ… Installed Groq SDK (groq==0.11.0) and updated requirements.txt
- âœ… Created comprehensive unit tests for all components (47 tests passing)
- âœ… Created test endpoint `/api/v1/llm-test/generate` to demonstrate provider usage across categories

**Phases 4-7 Status:**
The current counselor implementation uses PipeCat's built-in LLM services (GoogleLLMService, OpenAILLMService) which are tightly integrated into PipeCat's pipeline architecture. Full integration requires:

1. **Architecture Decision Needed:** Determine if we should:
   - A) Replace PipeCat's LLM services with our provider (requires custom PipeCat processor)
   - B) Use our provider for pre-processing/system prompt generation and keep PipeCat's services
   - C) Create a hybrid where our provider generates text that feeds into PipeCat's TTS directly

2. **Current Counselor Architecture:**
   - VoiceCounselorBot in `pipecat_bot/voice_bot.py` uses PipeCat's GoogleLLMService/OpenAILLMService
   - Avatar agent in `avatar_agent/` uses similar pattern
   - System prompts are category-specific but LLM integration is via PipeCat framework
   - All 6 categories (Health, Career, Academic, Financial, Social, PersonalDevelopment) share the same bot code with different prompts

### Debug Log

**2024-12-23 - Provider Abstraction Foundation Complete**
- Created complete provider abstraction layer with Groq and Gemini adapters
- All 47 unit tests passing for base, factory, groq_adapter, and gemini_adapter
- Factory correctly handles provider selection, caching, and fallback to Gemini
- Error handling covers rate limits, timeouts, invalid keys, and safety filters
- Test endpoint demonstrates provider working with all 6 counselor categories

**Next Steps Required:**
1. **Architectural Consultation:** Need PO/Tech Lead decision on PipeCat integration approach
2. **PipeCat Integration:** Once approach decided, refactor voice_bot.py to use provider
3. **Avatar Integration:** Refactor avatar_agent to use provider
4. **Integration Testing:** Test with real Groq/Gemini API keys and all 6 categories
5. **Concurrent Load Testing:** Verify 10+ simultaneous sessions work correctly
6. **Provider Switching Validation:** Test changing LLM_PROVIDER env var and restarting

**Test Summary:**
- âœ… 56 total tests passing (47 provider tests + 9 router tests)
- âœ… 100% coverage of base abstractions, adapters, and factory
- âœ… All error handling paths tested
- âœ… Test endpoint validates cross-category usage

### Completion Notes

**What's Working:**
- âœ… Provider abstraction layer fully functional
- âœ… Both Groq and Gemini adapters tested and working
- âœ… Factory pattern with singleton caching
- âœ… Test endpoint demonstrates cross-category usage
- âœ… Error handling for all provider error types
- âœ… Configuration via environment variables

**What Needs Completion:**
- âš ï¸ Integration with PipeCat voice framework (Tasks 5-11)
- âš ï¸ Integration with Beyond Presence avatar framework (Task 12)
- âš ï¸ Crisis detection integration (Task 13)
- âš ï¸ Comprehensive integration tests (Tasks 14-17)
- âš ï¸ Documentation for provider switching (Task 18)

**Blocked Items:**
- PipeCat/Avatar integration blocked on architectural decision about how to inject our provider into their pipeline frameworks

### File List

**Created:**
- packages/backend/app/providers/__init__.py (exports for provider package)
- packages/backend/app/providers/base.py (150 lines - abstract base class, LLMResponse, exceptions)
- packages/backend/app/providers/groq_adapter.py (165 lines - Groq implementation)
- packages/backend/app/providers/gemini_adapter.py (180 lines - Gemini implementation)
- packages/backend/app/providers/factory.py (130 lines - provider factory with singleton)
- packages/backend/tests/providers/__init__.py
- packages/backend/tests/providers/test_base.py (160 lines - 12 tests)
- packages/backend/tests/providers/test_groq_adapter.py (195 lines - 11 tests)
- packages/backend/tests/providers/test_gemini_adapter.py (210 lines - 13 tests)
- packages/backend/tests/providers/test_factory.py (220 lines - 11 tests)
- packages/backend/app/routers/llm_test.py (155 lines - test endpoint for demonstration)
- packages/backend/tests/test_llm_test_router.py (165 lines - 9 tests for test endpoint)
- packages/backend/app/providers/README.md (340 lines - comprehensive usage documentation)

**Modified:**
- packages/backend/app/config.py (added llm_provider, groq_api_key, gemini_api_key fields)
- packages/backend/app/main.py (registered llm_test router)
- packages/backend/requirements.txt (added groq==0.11.0)
- packages/backend/.env.example (added LLM_PROVIDER, GROQ_API_KEY, GEMINI_API_KEY)

### Change Log Additions

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2023-12-23 | 4.0 | Phases 1-3 implemented: Provider abstraction, Groq/Gemini adapters, Factory | James (Dev Agent) |

---

## QA Results

### Quality Gate: ðŸŸ¡ CONCERNS

**Reviewed by**: Quinn (Test Architect)  
**Date**: 2025-12-23  
**Gate Decision**: CONCERNS - Foundation excellent, integration incomplete

**Summary**: Provider abstraction layer is production-quality with 56/56 tests passing and excellent architecture. However, story is incomplete as the provider is not integrated with actual counselor agents (PipeCat/Avatar). Architectural decision needed before Tasks 5-18 can proceed.

---

### Requirements Traceability

**âœ… Completed (ACs 1-9, 16-18)**:
- AC 1-2: Abstract base class & LLMResponse âœ…
- AC 3: Groq adapter implementation âœ…
- AC 4: Gemini adapter implementation âœ…
- AC 5-9: Provider factory with env config âœ…
- AC 16-17: Logging & fallback behavior âœ…
- AC 18: Unit tests (56 tests, 100% passing) âœ…

**âš ï¸ Incomplete/Blocked (ACs 10-15, 19-22)**:
- AC 10-14: Counselor integration âŒ BLOCKED (awaiting architecture decision)
- AC 15: Provider switching âŒ NOT TESTED
- AC 19-20: Integration tests âŒ MISSING
- AC 21: Concurrent session testing âŒ NOT PERFORMED
- AC 22: Performance benchmarking âŒ NOT MEASURED

---

### Test Coverage Analysis

**Unit Tests**: âœ… **EXCELLENT** (56/56 passing, 100%)
- Base abstractions: 12 tests
- Groq adapter: 11 tests (all error scenarios)
- Gemini adapter: 13 tests (including safety filters)
- Factory: 11 tests (singleton, fallback, caching)
- Test router: 9 tests (cross-category demo)

**Integration Tests**: âŒ **MISSING**
- No tests with actual 6 counselor categories
- No PipeCat/Avatar integration tests
- No provider switching tests

**Load Tests**: âŒ **NOT PERFORMED**
- 10+ concurrent sessions requirement not tested
- Thread-safety unverified

---

### Top Issues

**ðŸ”´ INT-001 [HIGH]: Incomplete Integration**
- **Finding**: Provider abstraction not integrated with PipeCat voice bot or Avatar video agent
- **Impact**: Core functionality (AC 10-14) cannot be validated
- **Blocking**: Tasks 5-13 blocked on architectural decision
- **Recommendation**: MUST complete integration before production

**ðŸŸ¡ TEST-001 [MEDIUM]: Missing Integration Tests**
- **Finding**: No end-to-end tests with 6 counselor categories (AC 19-20)
- **Impact**: Cannot verify provider works in real usage scenarios
- **Recommendation**: Create integration test suite after counselor integration

**ðŸŸ¡ PERF-001 [MEDIUM]: Untested Concurrency**
- **Finding**: No concurrent load testing performed (AC 21)
- **Impact**: Thread-safety and resource conflicts unverified
- **Recommendation**: Test 10+ simultaneous sessions before production

---

### Non-Functional Requirements

**Security**: âš ï¸ CONCERNS
- âœ… No hardcoded credentials
- âœ… Error handling prevents leakage
- âš ï¸ No rate limiting
- âš ï¸ No key rotation mechanism

**Reliability**: âœ… PASS
- Comprehensive error handling
- Fallback mechanisms work

**Maintainability**: âœ… PASS
- Clean architecture
- Well documented
- Easy to extend

**Performance**: ðŸŸ¡ UNKNOWN
- <50ms overhead not benchmarked
- Likely acceptable but unverified

**Scalability**: âš ï¸ CONCERNS
- Concurrent behavior untested
- Connection pooling unverified

---

### Recommendations

**ðŸ”´ Must Fix Before Production**:
1. Complete architectural decision on PipeCat/Avatar integration
2. Implement Tasks 5-13 (integrate with all 6 counselor categories)
3. Create end-to-end integration test suite
4. Perform concurrent load testing (10+ sessions)
5. Validate provider switching in running system

**ðŸŸ¡ Should Address Soon**:
1. Add performance benchmarking
2. Implement rate limiting
3. Add API key rotation support
4. Enhance token tracking for Gemini

**âœ… Working Well**:
1. Provider abstraction design
2. Error handling
3. Unit test coverage
4. Documentation quality
5. Code maintainability

---

### Quality Metrics

- **Test Pass Rate**: 100% (56/56)
- **Code Coverage**: 100% (provider module)
- **Integration Coverage**: 0% (blocked)
- **Documentation**: Excellent (340-line README)
- **Maintainability**: High (clean architecture)

---

### Next Steps for Story Completion

1. **Architectural Decision** (1 day)
   - Choose PipeCat/Avatar integration approach
   - Document integration pattern

2. **Counselor Integration** (2-3 days)
   - Tasks 5-10: Refactor all 6 counselor categories
   - Tasks 11-13: Integrate with PipeCat/Avatar/Crisis detection

3. **Testing & Validation** (1-2 days)
   - Tasks 14-17: Integration, load, performance, switching tests
   - Task 18: Complete documentation

**Estimated Completion**: 4-6 days of focused work

---

### Gate File

See: [docs/qa/gates/7.1-llm-provider-abstraction.yml](../qa/gates/7.1-llm-provider-abstraction.yml)

---

## Summary

**Simplified Architecture:**

 **ONE provider configuration** (`LLM_PROVIDER=groq` or `LLM_PROVIDER=gemini`)  
 **All 6 counselor agents** use the same provider  
 **Easy switching:** Change env var, restart, done  
 **Works with:** PipeCat voice, Beyond Presence video, crisis detection  
 **Foundation for future:** Later stories can add automatic failover between providers

This story provides flexibility to switch between Groq and Gemini without code changes, while keeping the architecture simple and maintainable.
